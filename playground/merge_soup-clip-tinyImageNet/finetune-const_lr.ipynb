{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook:\n",
    "- takes the last checkpoint model trained by `finetune-clip-tinyImageNet/finetune-eval_model_soup.ipynb`, and continue fine-tune but using a constant learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLaqZVWVR4tE"
   },
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1756051719474,
     "user": {
      "displayName": "Yang Zhou",
      "userId": "09717432835810465973"
     },
     "user_tz": 240
    },
    "id": "NxzIeVi39G-1"
   },
   "outputs": [],
   "source": [
    "LOCAL = True\n",
    "\n",
    "# if run locally:\n",
    "if LOCAL:\n",
    "    ROOT_DIR = \"/Users/Yang/Desktop/research-model-merge/playground/merge_soup-clip-tinyImageNet\"\n",
    "    DATA_DIR = f\"{ROOT_DIR}/dataset\"\n",
    "    CODE_DIR = f\"{ROOT_DIR}/src\"\n",
    "# on Colab\n",
    "else:\n",
    "    ROOT_DIR = \"/content\"\n",
    "    DATA_DIR = \"/content\"\n",
    "    CODE_DIR = \"./clip_TinyImageNet\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1756051719516,
     "user": {
      "displayName": "Yang Zhou",
      "userId": "09717432835810465973"
     },
     "user_tz": 240
    },
    "id": "z5vVaNV99G-1"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(ROOT_DIR))\n",
    "sys.path.insert(0, os.path.abspath(CODE_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5O1BqBcz9G-2"
   },
   "source": [
    "If use Colab, you need to save output results to google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19655,
     "status": "ok",
     "timestamp": 1756051739176,
     "user": {
      "displayName": "Yang Zhou",
      "userId": "09717432835810465973"
     },
     "user_tz": 240
    },
    "id": "-GlMz92MR4tG",
    "outputId": "bd24bf3e-9aa9-40dc-a620-ee017df8a62f"
   },
   "outputs": [],
   "source": [
    "if not LOCAL:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DRIVE_DIR = \"drive/MyDrive/research-model_merge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orDTysBy9G-3"
   },
   "source": [
    "We will work under the same dir as this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K23WdGmnfvFA"
   },
   "source": [
    "To copy the code to fine-tune clip on tinyImageNet, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1542,
     "status": "ok",
     "timestamp": 1756051740719,
     "user": {
      "displayName": "Yang Zhou",
      "userId": "09717432835810465973"
     },
     "user_tz": 240
    },
    "id": "nTJAmIyofRi9",
    "outputId": "051dd08f-fb95-4c12-8308-3558216f8568"
   },
   "outputs": [],
   "source": [
    "if not LOCAL:\n",
    "    !git clone https://github.com/nbzy1995/clip_TinyImageNet.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AX1HKoALfFXS"
   },
   "source": [
    "To download tiny imagenet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 100958,
     "status": "ok",
     "timestamp": 1756051841679,
     "user": {
      "displayName": "Yang Zhou",
      "userId": "09717432835810465973"
     },
     "user_tz": 240
    },
    "id": "3uz63y5IdKYb"
   },
   "outputs": [],
   "source": [
    "if not LOCAL:\n",
    "    !wget -q http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
    "    !unzip -q tiny-imagenet-200.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRvGCTwr9G-3"
   },
   "source": [
    "Now we created a directory called \"tiny-imagenet-200\" containing the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3HW7EYqfgA8"
   },
   "source": [
    "We now copy pre-computed index for the train/ folder, 90% for training, 10% for validation. The val/ folder will be used as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1756051841715,
     "user": {
      "displayName": "Yang Zhou",
      "userId": "09717432835810465973"
     },
     "user_tz": 240
    },
    "id": "BOwhtbZZdOFf"
   },
   "outputs": [],
   "source": [
    "if not LOCAL:\n",
    "    !cp $CODE_DIR/dataset/tiny_imagenet_train_val_indices.npy /content/tiny_imagenet_train_val_indices.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8bVSnvX9G-4"
   },
   "source": [
    "Now we install the requirements for fine-tuning clip on tinyImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18766,
     "status": "ok",
     "timestamp": 1756051860490,
     "user": {
      "displayName": "Yang Zhou",
      "userId": "09717432835810465973"
     },
     "user_tz": 240
    },
    "id": "LWGC1rvTR4tH",
    "outputId": "450146f1-9ce5-41cf-e11c-9fec4fd0771c"
   },
   "outputs": [],
   "source": [
    "if not LOCAL:\n",
    "    !pip install --quiet --upgrade pip\n",
    "    !pip install -q -r clip_TinyImageNet/requirements.txt\n",
    "    print(\"✅ Core packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5308,
     "status": "ok",
     "timestamp": 1756051865800,
     "user": {
      "displayName": "Yang Zhou",
      "userId": "09717432835810465973"
     },
     "user_tz": 240
    },
    "id": "oe6uZ6LzR4tH",
    "outputId": "63ef4191-13f6-4153-ed4c-cb7168fb7f86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 System Information:\n",
      "Python version: Python 3.11.5\n",
      "PyTorch version: 2.8.0\n",
      "CUDA available: False\n",
      "❌ No GPU available! Please enable GPU runtime in Colab.\n",
      "Runtime > Change runtime type > Hardware accelerator > GPU\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability and system info\n",
    "import torch\n",
    "import subprocess\n",
    "\n",
    "print(\"🔍 System Information:\")\n",
    "print(f\"Python version: {subprocess.check_output(['python', '--version']).decode().strip()}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"❌ No GPU available! Please enable GPU runtime in Colab.\")\n",
    "    print(\"Runtime > Change runtime type > Hardware accelerator > GPU\")\n",
    "    DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmkIYFQuR4tI"
   },
   "source": [
    "## Fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from typing import List, Dict, Any, Sequence, Optional\n",
    "\n",
    "import torch\n",
    "import clip\n",
    "from tqdm import tqdm\n",
    "from timm.data.transforms_factory import transforms_imagenet_train\n",
    "\n",
    "from dataset.tiny_imagenet import TinyImageNet\n",
    "from src.utils import ModelWrapper, maybe_dictionarize_batch, cosine_lr\n",
    "\n",
    "\n",
    "def finetune_clip(\n",
    "    data_location: str = '.',\n",
    "    start_checkpoint_path: str = 'x.pt',\n",
    "    model_save_location: str = '.',\n",
    "    batch_size: int = 256,\n",
    "    workers: int = 8,\n",
    "    epochs: int = 10,\n",
    "    warmup_length: int = 500,\n",
    "    lr: float = 2e-5,\n",
    "    wd: float = 0.1,\n",
    "    model_name: str = 'ViT-B/32',\n",
    "    name: str = 'config1',\n",
    "    timm_aug: bool = False,\n",
    "    scheduler_type: str = 'cosine',  # 'cosine' or 'constant'\n",
    "    save_every: int = 1,\n",
    "    log_interval: int = 20,\n",
    "    grad_clip: float = 1.0,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Finetune CLIP on TinyImageNet inside notebook.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_location : str\n",
    "        Root directory containing Tiny ImageNet data (expects tiny-imagenet-200 folder or dataset loader handles path).\n",
    "    model_save_location : str\n",
    "        Directory to save checkpoints.\n",
    "    batch_size : int\n",
    "        Train batch size.\n",
    "    custom_template : bool\n",
    "        Use simple custom prompt template instead of OpenAI ImageNet template.\n",
    "    workers : int\n",
    "        DataLoader worker processes.\n",
    "    epochs : int\n",
    "        Number of epochs.\n",
    "    warmup_length : int\n",
    "        Warmup steps (only for cosine scheduler).\n",
    "    lr : float\n",
    "        Learning rate.\n",
    "    wd : float\n",
    "        Weight decay.\n",
    "    model_name : str\n",
    "        CLIP model name passed to clip.load.\n",
    "    name : str\n",
    "        Base filename prefix for checkpoints.\n",
    "    timm_aug : bool\n",
    "        Use timm ImageNet augmentation pipeline for training.\n",
    "    scheduler_type : str\n",
    "        'cosine' for cosine decay after warmup, 'constant' for fixed LR.\n",
    "    save_every : int\n",
    "        Save checkpoint every N epochs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    history: dict\n",
    "        train_loss per epoch, val_loss per epoch, val_acc per epoch, learning rate\n",
    "    \"\"\"\n",
    "    os.makedirs(model_save_location, exist_ok=True)\n",
    "\n",
    "    # # Prompt template\n",
    "    # template = openai_imagenet_template\n",
    "\n",
    "    # ---- Prepare dataset\n",
    "\n",
    "    clip_model, preprocess = clip.load(model_name, DEVICE, jit=False)\n",
    "\n",
    "    if timm_aug:\n",
    "        train_preprocess = transforms_imagenet_train(\n",
    "            img_size=clip_model.visual.input_resolution,\n",
    "            mean=(0.48145466, 0.4578275, 0.40821073),\n",
    "            std=(0.26862954, 0.26130258, 0.27577711),\n",
    "        )\n",
    "    else:\n",
    "        train_preprocess = preprocess\n",
    "\n",
    "    dset = TinyImageNet(\n",
    "        eval_preprocess=preprocess,\n",
    "        train_preprocess=train_preprocess,\n",
    "        location=data_location,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=workers,\n",
    "    )\n",
    "\n",
    "    num_classes = len(dset.classnames)\n",
    "    feature_dim = clip_model.visual.output_dim\n",
    "\n",
    "    # ---- Load model\n",
    "\n",
    "    # build image classifier model from clip model\n",
    "    model = ModelWrapper(clip_model, feature_dim, num_classes, normalize=True)\n",
    "    for p in model.parameters():\n",
    "        p.data = p.data.float()\n",
    "\n",
    "    print(f'Loading model state_dict from {start_checkpoint_path}')\n",
    "    checkpoint = torch.load(start_checkpoint_path, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    if DEVICE.type == 'cuda' and torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count())))\n",
    "\n",
    "    # ---- Optimizer\n",
    "    model_parameters = [p for p in model.parameters() if p.requires_grad]\n",
    "    print(f\"Training {sum(p.numel() for p in model_parameters):,} parameters\")\n",
    "    optimizer = torch.optim.AdamW(model_parameters, lr=lr, weight_decay=wd)\n",
    "\n",
    "    # ---- LR scheduler\n",
    "    num_batches = len(dset.train_loader)\n",
    "    if scheduler_type == 'cosine':\n",
    "        scheduler = cosine_lr(optimizer, lr, warmup_length, epochs * num_batches)\n",
    "    elif scheduler_type == 'constant':\n",
    "        def scheduler(step):\n",
    "            return  # no-op\n",
    "    else:\n",
    "        raise ValueError(\"scheduler_type must be 'cosine' or 'constant'\")\n",
    "    \n",
    "    # ---- Loss function\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # ---- Training loop\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        # 'delta_w': [], # magnitude of weights updates this epoch\n",
    "    }\n",
    "\n",
    "    # # Save initial weights (epoch 0 pre-training state)\n",
    "    # model_path = os.path.join(model_save_location, f'{name}_0.pt')\n",
    "    # model_state = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()\n",
    "    # torch.save(model_state, model_path)\n",
    "    # checkpoints.append(model_path)\n",
    "    # print('Saved initial model to', model_path)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        end = time.time()\n",
    "        for i, batch in enumerate(dset.train_loader):\n",
    "            step = i + epoch * num_batches\n",
    "            scheduler(step)\n",
    "            optimizer.zero_grad()\n",
    "            batch = maybe_dictionarize_batch(batch)\n",
    "            inputs, labels = batch['images'].to(DEVICE), batch['labels'].to(DEVICE)\n",
    "            data_time = time.time() - end\n",
    "\n",
    "            logits = model(inputs)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            batch_time = time.time() - end\n",
    "            end = time.time()\n",
    "\n",
    "            history['train_loss'].append(float(loss.item()))\n",
    "\n",
    "            if i % log_interval == 0:\n",
    "                percent_complete = 100.0 * i / num_batches\n",
    "                current_lr = optimizer.param_groups[0]['lr']\n",
    "                print(\n",
    "                    f\"Epoch {epoch} [{percent_complete:5.1f}% {i}/{num_batches}] \\t\"\n",
    "                    f\"Loss {loss.item():.4f} \\tLR {current_lr:.4g} \\tData {data_time:.3f}s Batch {batch_time:.3f}s\",\n",
    "                    flush=True,\n",
    "                )\n",
    "\n",
    "        # ---- Eval on Val set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print('*'*80)\n",
    "            print('Starting eval on validation split')\n",
    "            correct, count = 0.0, 0.0\n",
    "            val_loss_accum = 0.0\n",
    "            pbar = tqdm(dset.val_loader, desc=f'Val Epoch {epoch}')\n",
    "            for batch in pbar:\n",
    "                batch = maybe_dictionarize_batch(batch)\n",
    "                inputs, labels = batch['images'].to(DEVICE), batch['labels'].to(DEVICE)\n",
    "                logits = model(inputs)\n",
    "                loss = loss_fn(logits, labels)\n",
    "                val_loss_accum += loss.item() * len(labels)\n",
    "\n",
    "                pred = logits.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "                count += len(logits)\n",
    "                pbar.set_description(\n",
    "                    f\"Val loss: {loss.item():.4f}   Acc: {100*correct/count:.2f}\")\n",
    "                \n",
    "            top1 = correct / count\n",
    "            val_loss_mean = val_loss_accum / count\n",
    "        history['val_acc'].append(top1)\n",
    "        history['val_loss'].append(val_loss_mean)\n",
    "        print(f'Val acc at epoch {epoch}: {100*top1:.2f}% | Val loss: {val_loss_mean:.4f}')\n",
    "\n",
    "        # if (epoch + 1) % save_every == 0 or epoch == epochs - 1:\n",
    "        model_path = os.path.join(model_save_location, f'{name}_{epoch + 1}.pt')\n",
    "        model_state = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()\n",
    "        torch.save(model_state, model_path)\n",
    "        print('Saved model to', model_path)\n",
    "\n",
    "    result = {\n",
    "        'history': history,\n",
    "        'config': {\n",
    "            'data_location': data_location,\n",
    "            'model_save_location': model_save_location,\n",
    "            'batch_size': batch_size,\n",
    "            'workers': workers,\n",
    "            'epochs': epochs,\n",
    "            'warmup_length': warmup_length,\n",
    "            'lr': lr,\n",
    "            'wd': wd,\n",
    "            'model_name': model_name,\n",
    "            'name': name,\n",
    "            'timm_aug': timm_aug,\n",
    "            'scheduler_type': scheduler_type,\n",
    "        },\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run with config: {'lr': 3e-05, 'wd': 0.1, 'name': 'config1_10', 'start_checkpoint_path': 'checkpoints/config1_10.pt'}\n",
      "Run config: {'data_location': '/Users/Yang/Desktop/research-model-merge/playground/merge_soup-clip-tinyImageNet/dataset', 'model_save_location': 'checkpoints', 'batch_size': 256, 'epochs': 10, 'workers': 8, 'scheduler_type': 'constant', 'lr': 3e-05, 'wd': 0.1, 'name': 'config1_10', 'start_checkpoint_path': 'checkpoints/config1_10.pt'}\n",
      "Loading model state_dict from checkpoints/config1_10.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m run_config = {**common, **config}\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRun config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m result = \u001b[43mfinetune_clip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinished run with config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVal acc history: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mhistory\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mval_acc\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 107\u001b[39m, in \u001b[36mfinetune_clip\u001b[39m\u001b[34m(data_location, start_checkpoint_path, model_save_location, batch_size, workers, epochs, warmup_length, lr, wd, model_name, name, timm_aug, scheduler_type, save_every, log_interval, grad_clip)\u001b[39m\n\u001b[32m    104\u001b[39m     p.data = p.data.float()\n\u001b[32m    106\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mLoading model state_dict from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_checkpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m checkpoint = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_checkpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m model.load_state_dict(checkpoint)\n\u001b[32m    109\u001b[39m model = model.to(DEVICE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/research-model-merge/playground/merge_soup-clip-tinyImageNet/.venv/lib/python3.11/site-packages/torch/serialization.py:1521\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1519\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[32m   1520\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1521\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1528\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1529\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/research-model-merge/playground/merge_soup-clip-tinyImageNet/.venv/lib/python3.11/site-packages/torch/serialization.py:2119\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   2117\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[32m   2118\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m2119\u001b[39m result = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2120\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2122\u001b[39m torch._utils._validate_loaded_sparse_tensors()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/research-model-merge/playground/merge_soup-clip-tinyImageNet/.venv/lib/python3.11/site-packages/torch/_weights_only_unpickler.py:532\u001b[39m, in \u001b[36mUnpickler.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    525\u001b[39m         \u001b[38;5;28mtype\u001b[39m(pid) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\n\u001b[32m    526\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pid) > \u001b[32m0\u001b[39m\n\u001b[32m    527\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m torch.serialization._maybe_decode_ascii(pid[\u001b[32m0\u001b[39m]) != \u001b[33m\"\u001b[39m\u001b[33mstorage\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    528\u001b[39m     ):\n\u001b[32m    529\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[32m    530\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOnly persistent_load of storage is allowed, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    531\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     \u001b[38;5;28mself\u001b[39m.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpersistent_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[32m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [BINGET[\u001b[32m0\u001b[39m], LONG_BINGET[\u001b[32m0\u001b[39m]]:\n\u001b[32m    534\u001b[39m     idx = (read(\u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[32m0\u001b[39m] == BINGET[\u001b[32m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m unpack(\u001b[33m\"\u001b[39m\u001b[33m<I\u001b[39m\u001b[33m\"\u001b[39m, read(\u001b[32m4\u001b[39m)))[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/research-model-merge/playground/merge_soup-clip-tinyImageNet/.venv/lib/python3.11/site-packages/torch/serialization.py:2083\u001b[39m, in \u001b[36m_load.<locals>.persistent_load\u001b[39m\u001b[34m(saved_id)\u001b[39m\n\u001b[32m   2081\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2082\u001b[39m     nbytes = numel * torch._utils._element_size(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m2083\u001b[39m     typed_storage = \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2084\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2085\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2087\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/research-model-merge/playground/merge_soup-clip-tinyImageNet/.venv/lib/python3.11/site-packages/torch/serialization.py:2036\u001b[39m, in \u001b[36m_load.<locals>.load_tensor\u001b[39m\u001b[34m(dtype, numel, key, location)\u001b[39m\n\u001b[32m   2029\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m storage_offset != zip_file.get_record_offset(name):\n\u001b[32m   2030\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2031\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mThis is a debug assert that was run as the `TORCH_SERIALIZATION_DEBUG` environment \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2032\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvariable was set: Incorrect offset for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstorage_offset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m expected \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2033\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_file.get_record_offset(name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2034\u001b[39m             )\n\u001b[32m   2035\u001b[39m     storage = (\n\u001b[32m-> \u001b[39m\u001b[32m2036\u001b[39m         \u001b[43mzip_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2037\u001b[39m         ._typed_storage()\n\u001b[32m   2038\u001b[39m         ._untyped_storage\n\u001b[32m   2039\u001b[39m     )\n\u001b[32m   2040\u001b[39m \u001b[38;5;66;03m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[32m   2041\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m byteorderdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# We continue the training using const learning rate, from the previous cosline lr trained checkpoints, with same hyper param.\n",
    "checkpt_dir = f\"{DRIVE_DIR}/checkpoints\" if not LOCAL else './checkpoints'\n",
    "configs = [\n",
    "    dict(lr=3e-5, wd=0.1, name='config1_10', start_checkpoint_path=f\"{checkpt_dir}/config1_10.pt\"),\n",
    "    dict(lr=1e-5, wd=0.1, name='config2_10', start_checkpoint_path=f'{checkpt_dir}/config2_10.pt'),\n",
    "    dict(lr=3e-6, wd=0.1, name='config3_10', start_checkpoint_path=f'{checkpt_dir}/config3_10.pt'),\n",
    "    dict(lr=2e-5, wd=1e-3, name='config4_10', start_checkpoint_path=f'{checkpt_dir}/config4_10.pt'),\n",
    "    dict(lr=1e-6, wd=1e-4, name='config5_10', start_checkpoint_path=f'{checkpt_dir}/config5_10.pt'),\n",
    "]\n",
    "\n",
    "common = dict(\n",
    "    data_location=DATA_DIR,\n",
    "    model_save_location= checkpt_dir,\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    "    workers=2,\n",
    "    scheduler_type='constant',  # change to 'constant' for constant LR\n",
    ")\n",
    "\n",
    "\n",
    "for config in configs:\n",
    "    run_config = {**common, **config}\n",
    "    print(f\"Running with config: {run_config['name']}\")\n",
    "    print(run_config)\n",
    "    result = finetune_clip(**run_config)\n",
    "\n",
    "    print(\"✅ Config run completed and backed up to Drive!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# summary = []\n",
    "# for r in sweep_results:\n",
    "#     cfg = r['config']\n",
    "#     summary.append({\n",
    "#         'name': cfg['name'],\n",
    "#         'lr': cfg['lr'],\n",
    "#         'wd': cfg['wd'],\n",
    "#         'timm_aug': cfg['timm_aug'],\n",
    "#         'final_val_acc': r['val_acc_final'],\n",
    "#         'final_ckpt': r['final_checkpoint']\n",
    "#     })\n",
    "# df = pd.DataFrame(summary)\n",
    "# display(df)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same setup as `finetune-eval_model_soup.ipynb`.\n",
    "Hyperparameter Configurations:\n",
    "1. **Config 1**: lr=3e-5, wd=0.1, epochs=10, batch_size=256\n",
    "2. **Config 2**: lr=1e-5, wd=0.1, epochs=10, batch_size=256\n",
    "3. **Config 3**: lr=3e-6, wd=0.1, epochs=10, batch_size=256\n",
    "4. **Config 4**: lr=2e-5, wd=1e-3, epochs=10, batch_size=256\n",
    "5. **Config 5**: lr=1e-6, wd=1e-4, epochs=10, batch_size=256\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7996557,
     "status": "ok",
     "timestamp": 1755927931673,
     "user": {
      "displayName": "Yang Zhou",
      "userId": "09717432835810465973"
     },
     "user_tz": 240
    },
    "id": "fmT6QvCNR4tI",
    "outputId": "f1ddc423-6b26-4567-84ca-be3d0868b525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Building zero-shot classifier.\n",
      "100% 200/200 [00:10<00:00, 18.22it/s]\n",
      "Saving model to ./config1_0.pt\n",
      "Train Epoch: 0 [0% 0/352]\tLoss: 1.442926\tData (t) 11.733\tBatch (t) 15.286\n",
      "Train Epoch: 0 [6% 20/352]\tLoss: 1.261179\tData (t) 2.040\tBatch (t) 2.307\n",
      "Train Epoch: 0 [11% 40/352]\tLoss: 0.963566\tData (t) 1.796\tBatch (t) 2.055\n",
      "Train Epoch: 0 [17% 60/352]\tLoss: 1.013636\tData (t) 2.045\tBatch (t) 2.076\n",
      "Train Epoch: 0 [23% 80/352]\tLoss: 0.916063\tData (t) 2.007\tBatch (t) 2.073\n",
      "Train Epoch: 0 [28% 100/352]\tLoss: 0.836356\tData (t) 1.816\tBatch (t) 2.080\n",
      "Train Epoch: 0 [34% 120/352]\tLoss: 1.102863\tData (t) 2.034\tBatch (t) 2.066\n",
      "Train Epoch: 0 [40% 140/352]\tLoss: 0.925082\tData (t) 2.032\tBatch (t) 2.065\n",
      "Train Epoch: 0 [45% 160/352]\tLoss: 1.065236\tData (t) 2.039\tBatch (t) 2.070\n",
      "Train Epoch: 0 [51% 180/352]\tLoss: 0.848087\tData (t) 2.037\tBatch (t) 2.069\n",
      "Train Epoch: 0 [57% 200/352]\tLoss: 0.978953\tData (t) 1.815\tBatch (t) 1.847\n",
      "Train Epoch: 0 [62% 220/352]\tLoss: 0.807766\tData (t) 1.821\tBatch (t) 1.855\n",
      "Train Epoch: 0 [68% 240/352]\tLoss: 0.923739\tData (t) 1.823\tBatch (t) 1.855\n",
      "Train Epoch: 0 [74% 260/352]\tLoss: 0.964957\tData (t) 2.036\tBatch (t) 2.068\n",
      "Train Epoch: 0 [80% 280/352]\tLoss: 0.844073\tData (t) 2.034\tBatch (t) 2.065\n",
      "Train Epoch: 0 [85% 300/352]\tLoss: 1.044112\tData (t) 2.032\tBatch (t) 2.064\n",
      "Train Epoch: 0 [91% 320/352]\tLoss: 0.882609\tData (t) 2.031\tBatch (t) 2.291\n",
      "Train Epoch: 0 [97% 340/352]\tLoss: 0.833859\tData (t) 1.805\tBatch (t) 1.836\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.2707   Acc: 76.22: 100% 40/40 [00:38<00:00,  1.05it/s]\n",
      "Val acc at epoch 0: 76.22\n",
      "Saving model to ./config1_1.pt\n",
      "Train Epoch: 1 [0% 0/352]\tLoss: 0.714028\tData (t) 7.058\tBatch (t) 7.929\n",
      "Train Epoch: 1 [6% 20/352]\tLoss: 0.507759\tData (t) 2.060\tBatch (t) 2.092\n",
      "Train Epoch: 1 [11% 40/352]\tLoss: 0.748859\tData (t) 2.018\tBatch (t) 2.050\n",
      "Train Epoch: 1 [17% 60/352]\tLoss: 0.869590\tData (t) 2.047\tBatch (t) 2.199\n",
      "Train Epoch: 1 [23% 80/352]\tLoss: 0.740386\tData (t) 1.976\tBatch (t) 2.008\n",
      "Train Epoch: 1 [28% 100/352]\tLoss: 0.563878\tData (t) 2.015\tBatch (t) 2.056\n",
      "Train Epoch: 1 [34% 120/352]\tLoss: 0.764934\tData (t) 2.021\tBatch (t) 2.076\n",
      "Train Epoch: 1 [40% 140/352]\tLoss: 0.773874\tData (t) 2.034\tBatch (t) 2.077\n",
      "Train Epoch: 1 [45% 160/352]\tLoss: 0.673568\tData (t) 2.036\tBatch (t) 2.079\n",
      "Train Epoch: 1 [51% 180/352]\tLoss: 0.758510\tData (t) 2.034\tBatch (t) 2.100\n",
      "Train Epoch: 1 [57% 200/352]\tLoss: 0.709141\tData (t) 1.928\tBatch (t) 2.142\n",
      "Train Epoch: 1 [62% 220/352]\tLoss: 0.764736\tData (t) 1.831\tBatch (t) 1.863\n",
      "Train Epoch: 1 [68% 240/352]\tLoss: 0.682794\tData (t) 2.034\tBatch (t) 2.066\n",
      "Train Epoch: 1 [74% 260/352]\tLoss: 0.684872\tData (t) 2.039\tBatch (t) 2.072\n",
      "Train Epoch: 1 [80% 280/352]\tLoss: 0.704220\tData (t) 2.038\tBatch (t) 2.069\n",
      "Train Epoch: 1 [85% 300/352]\tLoss: 0.671935\tData (t) 2.037\tBatch (t) 2.095\n",
      "Train Epoch: 1 [91% 320/352]\tLoss: 0.613728\tData (t) 2.019\tBatch (t) 2.050\n",
      "Train Epoch: 1 [97% 340/352]\tLoss: 0.743365\tData (t) 2.041\tBatch (t) 2.072\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.1198   Acc: 75.04: 100% 40/40 [00:34<00:00,  1.15it/s]\n",
      "Val acc at epoch 1: 75.04\n",
      "Saving model to ./config1_2.pt\n",
      "Train Epoch: 2 [0% 0/352]\tLoss: 0.496453\tData (t) 6.567\tBatch (t) 6.931\n",
      "Train Epoch: 2 [6% 20/352]\tLoss: 0.396248\tData (t) 2.074\tBatch (t) 2.121\n",
      "Train Epoch: 2 [11% 40/352]\tLoss: 0.413617\tData (t) 2.017\tBatch (t) 2.059\n",
      "Train Epoch: 2 [17% 60/352]\tLoss: 0.457554\tData (t) 2.051\tBatch (t) 2.223\n",
      "Train Epoch: 2 [23% 80/352]\tLoss: 0.552157\tData (t) 2.032\tBatch (t) 2.077\n",
      "Train Epoch: 2 [28% 100/352]\tLoss: 0.398652\tData (t) 2.040\tBatch (t) 2.071\n",
      "Train Epoch: 2 [34% 120/352]\tLoss: 0.404064\tData (t) 2.042\tBatch (t) 2.073\n",
      "Train Epoch: 2 [40% 140/352]\tLoss: 0.401470\tData (t) 2.041\tBatch (t) 2.072\n",
      "Train Epoch: 2 [45% 160/352]\tLoss: 0.463397\tData (t) 2.030\tBatch (t) 2.069\n",
      "Train Epoch: 2 [51% 180/352]\tLoss: 0.514588\tData (t) 2.034\tBatch (t) 2.065\n",
      "Train Epoch: 2 [57% 200/352]\tLoss: 0.454806\tData (t) 2.033\tBatch (t) 2.066\n",
      "Train Epoch: 2 [62% 220/352]\tLoss: 0.375516\tData (t) 2.034\tBatch (t) 2.081\n",
      "Train Epoch: 2 [68% 240/352]\tLoss: 0.522849\tData (t) 2.035\tBatch (t) 2.072\n",
      "Train Epoch: 2 [74% 260/352]\tLoss: 0.368076\tData (t) 2.038\tBatch (t) 2.221\n",
      "Train Epoch: 2 [80% 280/352]\tLoss: 0.333889\tData (t) 1.864\tBatch (t) 1.896\n",
      "Train Epoch: 2 [85% 300/352]\tLoss: 0.344610\tData (t) 2.037\tBatch (t) 2.068\n",
      "Train Epoch: 2 [91% 320/352]\tLoss: 0.497864\tData (t) 2.042\tBatch (t) 2.074\n",
      "Train Epoch: 2 [97% 340/352]\tLoss: 0.402224\tData (t) 1.873\tBatch (t) 1.916\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.8136   Acc: 76.80: 100% 40/40 [00:36<00:00,  1.10it/s]\n",
      "Val acc at epoch 2: 76.80\n",
      "Saving model to ./config1_3.pt\n",
      "Train Epoch: 3 [0% 0/352]\tLoss: 0.185093\tData (t) 6.628\tBatch (t) 6.914\n",
      "Train Epoch: 3 [6% 20/352]\tLoss: 0.137882\tData (t) 2.063\tBatch (t) 2.099\n",
      "Train Epoch: 3 [11% 40/352]\tLoss: 0.238177\tData (t) 2.004\tBatch (t) 2.044\n",
      "Train Epoch: 3 [17% 60/352]\tLoss: 0.279114\tData (t) 2.033\tBatch (t) 2.081\n",
      "Train Epoch: 3 [23% 80/352]\tLoss: 0.269158\tData (t) 2.017\tBatch (t) 2.048\n",
      "Train Epoch: 3 [28% 100/352]\tLoss: 0.328763\tData (t) 1.998\tBatch (t) 2.047\n",
      "Train Epoch: 3 [34% 120/352]\tLoss: 0.246874\tData (t) 2.023\tBatch (t) 2.075\n",
      "Train Epoch: 3 [40% 140/352]\tLoss: 0.256330\tData (t) 2.012\tBatch (t) 2.058\n",
      "Train Epoch: 3 [45% 160/352]\tLoss: 0.218323\tData (t) 1.855\tBatch (t) 2.088\n",
      "Train Epoch: 3 [51% 180/352]\tLoss: 0.238956\tData (t) 1.840\tBatch (t) 2.072\n",
      "Train Epoch: 3 [57% 200/352]\tLoss: 0.258622\tData (t) 2.034\tBatch (t) 2.083\n",
      "Train Epoch: 3 [62% 220/352]\tLoss: 0.220502\tData (t) 1.963\tBatch (t) 2.009\n",
      "Train Epoch: 3 [68% 240/352]\tLoss: 0.230731\tData (t) 2.021\tBatch (t) 2.074\n",
      "Train Epoch: 3 [74% 260/352]\tLoss: 0.263673\tData (t) 2.024\tBatch (t) 2.070\n",
      "Train Epoch: 3 [80% 280/352]\tLoss: 0.267900\tData (t) 2.022\tBatch (t) 2.063\n",
      "Train Epoch: 3 [85% 300/352]\tLoss: 0.198898\tData (t) 2.017\tBatch (t) 2.069\n",
      "Train Epoch: 3 [91% 320/352]\tLoss: 0.197539\tData (t) 2.032\tBatch (t) 2.064\n",
      "Train Epoch: 3 [97% 340/352]\tLoss: 0.334714\tData (t) 2.026\tBatch (t) 2.058\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.0995   Acc: 77.14: 100% 40/40 [00:34<00:00,  1.16it/s]\n",
      "Val acc at epoch 3: 77.14\n",
      "Saving model to ./config1_4.pt\n",
      "Train Epoch: 4 [0% 0/352]\tLoss: 0.058337\tData (t) 6.106\tBatch (t) 6.500\n",
      "Train Epoch: 4 [6% 20/352]\tLoss: 0.114853\tData (t) 2.049\tBatch (t) 2.092\n",
      "Train Epoch: 4 [11% 40/352]\tLoss: 0.096688\tData (t) 2.017\tBatch (t) 2.049\n",
      "Train Epoch: 4 [17% 60/352]\tLoss: 0.152249\tData (t) 2.038\tBatch (t) 2.069\n",
      "Train Epoch: 4 [23% 80/352]\tLoss: 0.252231\tData (t) 2.034\tBatch (t) 2.065\n",
      "Train Epoch: 4 [28% 100/352]\tLoss: 0.076533\tData (t) 2.035\tBatch (t) 2.068\n",
      "Train Epoch: 4 [34% 120/352]\tLoss: 0.132971\tData (t) 2.032\tBatch (t) 2.064\n",
      "Train Epoch: 4 [40% 140/352]\tLoss: 0.092438\tData (t) 2.041\tBatch (t) 2.072\n",
      "Train Epoch: 4 [45% 160/352]\tLoss: 0.125334\tData (t) 2.038\tBatch (t) 2.075\n",
      "Train Epoch: 4 [51% 180/352]\tLoss: 0.060519\tData (t) 2.034\tBatch (t) 2.225\n",
      "Train Epoch: 4 [57% 200/352]\tLoss: 0.086647\tData (t) 1.878\tBatch (t) 2.191\n",
      "Train Epoch: 4 [62% 220/352]\tLoss: 0.104377\tData (t) 1.900\tBatch (t) 2.196\n",
      "Train Epoch: 4 [68% 240/352]\tLoss: 0.100532\tData (t) 1.907\tBatch (t) 1.939\n",
      "Train Epoch: 4 [74% 260/352]\tLoss: 0.177138\tData (t) 1.976\tBatch (t) 2.011\n",
      "Train Epoch: 4 [80% 280/352]\tLoss: 0.149915\tData (t) 1.980\tBatch (t) 2.012\n",
      "Train Epoch: 4 [85% 300/352]\tLoss: 0.191410\tData (t) 2.025\tBatch (t) 2.056\n",
      "Train Epoch: 4 [91% 320/352]\tLoss: 0.138626\tData (t) 2.016\tBatch (t) 2.052\n",
      "Train Epoch: 4 [97% 340/352]\tLoss: 0.097233\tData (t) 2.025\tBatch (t) 2.056\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.3845   Acc: 76.99: 100% 40/40 [00:42<00:00,  1.06s/it]\n",
      "Val acc at epoch 4: 76.99\n",
      "Saving model to ./config1_5.pt\n",
      "Train Epoch: 5 [0% 0/352]\tLoss: 0.047342\tData (t) 5.888\tBatch (t) 6.208\n",
      "Train Epoch: 5 [6% 20/352]\tLoss: 0.045724\tData (t) 2.045\tBatch (t) 2.076\n",
      "Train Epoch: 5 [11% 40/352]\tLoss: 0.036104\tData (t) 2.012\tBatch (t) 2.043\n",
      "Train Epoch: 5 [17% 60/352]\tLoss: 0.092604\tData (t) 2.044\tBatch (t) 2.104\n",
      "Train Epoch: 5 [23% 80/352]\tLoss: 0.075031\tData (t) 2.032\tBatch (t) 2.065\n",
      "Train Epoch: 5 [28% 100/352]\tLoss: 0.059714\tData (t) 2.038\tBatch (t) 2.075\n",
      "Train Epoch: 5 [34% 120/352]\tLoss: 0.033275\tData (t) 2.034\tBatch (t) 2.066\n",
      "Train Epoch: 5 [40% 140/352]\tLoss: 0.085656\tData (t) 2.036\tBatch (t) 2.068\n",
      "Train Epoch: 5 [45% 160/352]\tLoss: 0.072312\tData (t) 1.986\tBatch (t) 2.020\n",
      "Train Epoch: 5 [51% 180/352]\tLoss: 0.082576\tData (t) 2.042\tBatch (t) 2.072\n",
      "Train Epoch: 5 [57% 200/352]\tLoss: 0.071426\tData (t) 2.038\tBatch (t) 2.071\n",
      "Train Epoch: 5 [62% 220/352]\tLoss: 0.085166\tData (t) 2.036\tBatch (t) 2.069\n",
      "Train Epoch: 5 [68% 240/352]\tLoss: 0.064636\tData (t) 2.038\tBatch (t) 2.070\n",
      "Train Epoch: 5 [74% 260/352]\tLoss: 0.050800\tData (t) 2.027\tBatch (t) 2.066\n",
      "Train Epoch: 5 [80% 280/352]\tLoss: 0.077679\tData (t) 2.046\tBatch (t) 2.077\n",
      "Train Epoch: 5 [85% 300/352]\tLoss: 0.092337\tData (t) 2.042\tBatch (t) 2.073\n",
      "Train Epoch: 5 [91% 320/352]\tLoss: 0.061193\tData (t) 2.034\tBatch (t) 2.066\n",
      "Train Epoch: 5 [97% 340/352]\tLoss: 0.042397\tData (t) 2.027\tBatch (t) 2.058\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.6287   Acc: 77.96: 100% 40/40 [00:37<00:00,  1.08it/s]\n",
      "Val acc at epoch 5: 77.96\n",
      "Saving model to ./config1_6.pt\n",
      "Train Epoch: 6 [0% 0/352]\tLoss: 0.061105\tData (t) 8.624\tBatch (t) 8.914\n",
      "Train Epoch: 6 [6% 20/352]\tLoss: 0.014794\tData (t) 1.919\tBatch (t) 1.951\n",
      "Train Epoch: 6 [11% 40/352]\tLoss: 0.024344\tData (t) 1.793\tBatch (t) 1.824\n",
      "Train Epoch: 6 [17% 60/352]\tLoss: 0.028481\tData (t) 1.858\tBatch (t) 1.889\n",
      "Train Epoch: 6 [23% 80/352]\tLoss: 0.020336\tData (t) 1.788\tBatch (t) 1.829\n",
      "Train Epoch: 6 [28% 100/352]\tLoss: 0.066957\tData (t) 2.017\tBatch (t) 2.048\n",
      "Train Epoch: 6 [34% 120/352]\tLoss: 0.033540\tData (t) 1.963\tBatch (t) 1.994\n",
      "Train Epoch: 6 [40% 140/352]\tLoss: 0.043989\tData (t) 2.041\tBatch (t) 2.073\n",
      "Train Epoch: 6 [45% 160/352]\tLoss: 0.015840\tData (t) 2.036\tBatch (t) 2.068\n",
      "Train Epoch: 6 [51% 180/352]\tLoss: 0.010376\tData (t) 2.040\tBatch (t) 2.072\n",
      "Train Epoch: 6 [57% 200/352]\tLoss: 0.029828\tData (t) 2.039\tBatch (t) 2.076\n",
      "Train Epoch: 6 [62% 220/352]\tLoss: 0.019020\tData (t) 2.028\tBatch (t) 2.070\n",
      "Train Epoch: 6 [68% 240/352]\tLoss: 0.011406\tData (t) 2.041\tBatch (t) 2.072\n",
      "Train Epoch: 6 [74% 260/352]\tLoss: 0.019642\tData (t) 2.030\tBatch (t) 2.241\n",
      "Train Epoch: 6 [80% 280/352]\tLoss: 0.016148\tData (t) 1.878\tBatch (t) 1.910\n",
      "Train Epoch: 6 [85% 300/352]\tLoss: 0.027405\tData (t) 2.040\tBatch (t) 2.071\n",
      "Train Epoch: 6 [91% 320/352]\tLoss: 0.024107\tData (t) 2.038\tBatch (t) 2.069\n",
      "Train Epoch: 6 [97% 340/352]\tLoss: 0.047117\tData (t) 2.039\tBatch (t) 2.071\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.1376   Acc: 79.21: 100% 40/40 [00:39<00:00,  1.02it/s]\n",
      "Val acc at epoch 6: 79.21\n",
      "Saving model to ./config1_7.pt\n",
      "Train Epoch: 7 [0% 0/352]\tLoss: 0.008159\tData (t) 8.975\tBatch (t) 9.266\n",
      "Train Epoch: 7 [6% 20/352]\tLoss: 0.002781\tData (t) 2.047\tBatch (t) 2.080\n",
      "Train Epoch: 7 [11% 40/352]\tLoss: 0.004646\tData (t) 2.030\tBatch (t) 2.061\n",
      "Train Epoch: 7 [17% 60/352]\tLoss: 0.008357\tData (t) 2.037\tBatch (t) 2.068\n",
      "Train Epoch: 7 [23% 80/352]\tLoss: 0.006591\tData (t) 2.032\tBatch (t) 2.063\n",
      "Train Epoch: 7 [28% 100/352]\tLoss: 0.005889\tData (t) 2.033\tBatch (t) 2.064\n",
      "Train Epoch: 7 [34% 120/352]\tLoss: 0.013710\tData (t) 1.864\tBatch (t) 1.896\n",
      "Train Epoch: 7 [40% 140/352]\tLoss: 0.011587\tData (t) 2.035\tBatch (t) 2.066\n",
      "Train Epoch: 7 [45% 160/352]\tLoss: 0.031828\tData (t) 2.040\tBatch (t) 2.072\n",
      "Train Epoch: 7 [51% 180/352]\tLoss: 0.005371\tData (t) 2.034\tBatch (t) 2.065\n",
      "Train Epoch: 7 [57% 200/352]\tLoss: 0.006831\tData (t) 2.032\tBatch (t) 2.063\n",
      "Train Epoch: 7 [62% 220/352]\tLoss: 0.001469\tData (t) 2.037\tBatch (t) 2.069\n",
      "Train Epoch: 7 [68% 240/352]\tLoss: 0.004138\tData (t) 1.921\tBatch (t) 1.952\n",
      "Train Epoch: 7 [74% 260/352]\tLoss: 0.002297\tData (t) 2.036\tBatch (t) 2.069\n",
      "Train Epoch: 7 [80% 280/352]\tLoss: 0.001525\tData (t) 2.035\tBatch (t) 2.071\n",
      "Train Epoch: 7 [85% 300/352]\tLoss: 0.003119\tData (t) 2.031\tBatch (t) 2.063\n",
      "Train Epoch: 7 [91% 320/352]\tLoss: 0.001227\tData (t) 2.038\tBatch (t) 2.070\n",
      "Train Epoch: 7 [97% 340/352]\tLoss: 0.004459\tData (t) 2.035\tBatch (t) 2.154\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.2098   Acc: 80.45: 100% 40/40 [00:36<00:00,  1.09it/s]\n",
      "Val acc at epoch 7: 80.45\n",
      "Saving model to ./config1_8.pt\n",
      "Train Epoch: 8 [0% 0/352]\tLoss: 0.000716\tData (t) 7.575\tBatch (t) 8.187\n",
      "Train Epoch: 8 [6% 20/352]\tLoss: 0.000996\tData (t) 1.741\tBatch (t) 1.805\n",
      "Train Epoch: 8 [11% 40/352]\tLoss: 0.000775\tData (t) 1.752\tBatch (t) 1.845\n",
      "Train Epoch: 8 [17% 60/352]\tLoss: 0.000873\tData (t) 1.931\tBatch (t) 1.973\n",
      "Train Epoch: 8 [23% 80/352]\tLoss: 0.001172\tData (t) 2.020\tBatch (t) 2.070\n",
      "Train Epoch: 8 [28% 100/352]\tLoss: 0.001098\tData (t) 2.020\tBatch (t) 2.051\n",
      "Train Epoch: 8 [34% 120/352]\tLoss: 0.000632\tData (t) 2.036\tBatch (t) 2.067\n",
      "Train Epoch: 8 [40% 140/352]\tLoss: 0.000564\tData (t) 2.031\tBatch (t) 2.063\n",
      "Train Epoch: 8 [45% 160/352]\tLoss: 0.000364\tData (t) 2.040\tBatch (t) 2.072\n",
      "Train Epoch: 8 [51% 180/352]\tLoss: 0.000722\tData (t) 2.035\tBatch (t) 2.066\n",
      "Train Epoch: 8 [57% 200/352]\tLoss: 0.000501\tData (t) 2.037\tBatch (t) 2.068\n",
      "Train Epoch: 8 [62% 220/352]\tLoss: 0.000525\tData (t) 2.035\tBatch (t) 2.066\n",
      "Train Epoch: 8 [68% 240/352]\tLoss: 0.001946\tData (t) 2.037\tBatch (t) 2.068\n",
      "Train Epoch: 8 [74% 260/352]\tLoss: 0.000951\tData (t) 2.038\tBatch (t) 2.069\n",
      "Train Epoch: 8 [80% 280/352]\tLoss: 0.000752\tData (t) 2.026\tBatch (t) 2.064\n",
      "Train Epoch: 8 [85% 300/352]\tLoss: 0.000764\tData (t) 2.035\tBatch (t) 2.065\n",
      "Train Epoch: 8 [91% 320/352]\tLoss: 0.000533\tData (t) 2.036\tBatch (t) 2.067\n",
      "Train Epoch: 8 [97% 340/352]\tLoss: 0.000545\tData (t) 2.034\tBatch (t) 2.065\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.1265   Acc: 81.25: 100% 40/40 [00:36<00:00,  1.10it/s]\n",
      "Val acc at epoch 8: 81.25\n",
      "Saving model to ./config1_9.pt\n",
      "Train Epoch: 9 [0% 0/352]\tLoss: 0.000439\tData (t) 6.750\tBatch (t) 7.117\n",
      "Train Epoch: 9 [6% 20/352]\tLoss: 0.000270\tData (t) 2.056\tBatch (t) 2.088\n",
      "Train Epoch: 9 [11% 40/352]\tLoss: 0.000328\tData (t) 2.013\tBatch (t) 2.046\n",
      "Train Epoch: 9 [17% 60/352]\tLoss: 0.000288\tData (t) 2.044\tBatch (t) 2.075\n",
      "Train Epoch: 9 [23% 80/352]\tLoss: 0.000402\tData (t) 2.037\tBatch (t) 2.094\n",
      "Train Epoch: 9 [28% 100/352]\tLoss: 0.000474\tData (t) 2.028\tBatch (t) 2.076\n",
      "Train Epoch: 9 [34% 120/352]\tLoss: 0.000287\tData (t) 2.026\tBatch (t) 2.057\n",
      "Train Epoch: 9 [40% 140/352]\tLoss: 0.000230\tData (t) 2.029\tBatch (t) 2.061\n",
      "Train Epoch: 9 [45% 160/352]\tLoss: 0.000326\tData (t) 2.025\tBatch (t) 2.056\n",
      "Train Epoch: 9 [51% 180/352]\tLoss: 0.000268\tData (t) 2.022\tBatch (t) 2.058\n",
      "Train Epoch: 9 [57% 200/352]\tLoss: 0.000349\tData (t) 1.715\tBatch (t) 2.000\n",
      "Train Epoch: 9 [62% 220/352]\tLoss: 0.000367\tData (t) 1.827\tBatch (t) 1.880\n",
      "Train Epoch: 9 [68% 240/352]\tLoss: 0.000300\tData (t) 2.012\tBatch (t) 2.043\n",
      "Train Epoch: 9 [74% 260/352]\tLoss: 0.000256\tData (t) 2.028\tBatch (t) 2.061\n",
      "Train Epoch: 9 [80% 280/352]\tLoss: 0.000301\tData (t) 2.036\tBatch (t) 2.070\n",
      "Train Epoch: 9 [85% 300/352]\tLoss: 0.000332\tData (t) 2.038\tBatch (t) 2.069\n",
      "Train Epoch: 9 [91% 320/352]\tLoss: 0.000384\tData (t) 2.018\tBatch (t) 2.065\n",
      "Train Epoch: 9 [97% 340/352]\tLoss: 0.000284\tData (t) 2.035\tBatch (t) 2.066\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.1076   Acc: 81.26: 100% 40/40 [00:34<00:00,  1.15it/s]\n",
      "Val acc at epoch 9: 81.26\n",
      "Saving model to ./config1_10.pt\n",
      "✅ Configuration 1 completed and backed up to Drive!\n"
     ]
    }
   ],
   "source": [
    "# Configuration 1: lr=3e-5, wd=0.1, epochs=10, batch_size=256, timm_aug=False\n",
    "!python $CODE_DIR/finetune.py --lr 3e-5 --wd 0.1 --epochs 10 --batch-size 256 --data-location $DATA_DIR --name \"config1\"\n",
    "\n",
    "# Backup model to Google Drive\n",
    "!cp config1_*.pt \"/content/drive/MyDrive/Colab Notebooks/\"\n",
    "print(\"✅ Configuration 1 completed and backed up to Drive!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8097860,
     "status": "ok",
     "timestamp": 1755936029540,
     "user": {
      "displayName": "Yang Zhou",
      "userId": "09717432835810465973"
     },
     "user_tz": 240
    },
    "id": "4GPdoKxdvedb",
    "outputId": "762602a7-ff3c-4c93-df26-d1000771a561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Building zero-shot classifier.\n",
      "100% 200/200 [00:11<00:00, 17.68it/s]\n",
      "Saving model to ./config2_0.pt\n",
      "Train Epoch: 0 [0% 0/352]\tLoss: 1.667826\tData (t) 14.185\tBatch (t) 20.316\n",
      "Train Epoch: 0 [6% 20/352]\tLoss: 1.226475\tData (t) 1.959\tBatch (t) 2.005\n",
      "Train Epoch: 0 [11% 40/352]\tLoss: 1.347273\tData (t) 2.024\tBatch (t) 2.088\n",
      "Train Epoch: 0 [17% 60/352]\tLoss: 1.134597\tData (t) 2.014\tBatch (t) 2.060\n",
      "Train Epoch: 0 [23% 80/352]\tLoss: 0.934149\tData (t) 2.039\tBatch (t) 2.070\n",
      "Train Epoch: 0 [28% 100/352]\tLoss: 0.970417\tData (t) 2.030\tBatch (t) 2.078\n",
      "Train Epoch: 0 [34% 120/352]\tLoss: 1.104056\tData (t) 2.029\tBatch (t) 2.062\n",
      "Train Epoch: 0 [40% 140/352]\tLoss: 1.082346\tData (t) 2.034\tBatch (t) 2.065\n",
      "Train Epoch: 0 [45% 160/352]\tLoss: 0.980819\tData (t) 2.032\tBatch (t) 2.063\n",
      "Train Epoch: 0 [51% 180/352]\tLoss: 0.824228\tData (t) 2.032\tBatch (t) 2.063\n",
      "Train Epoch: 0 [57% 200/352]\tLoss: 1.084069\tData (t) 2.031\tBatch (t) 2.061\n",
      "Train Epoch: 0 [62% 220/352]\tLoss: 1.013503\tData (t) 2.032\tBatch (t) 2.063\n",
      "Train Epoch: 0 [68% 240/352]\tLoss: 0.845630\tData (t) 2.029\tBatch (t) 2.060\n",
      "Train Epoch: 0 [74% 260/352]\tLoss: 0.688177\tData (t) 2.041\tBatch (t) 2.072\n",
      "Train Epoch: 0 [80% 280/352]\tLoss: 0.853603\tData (t) 2.038\tBatch (t) 2.069\n",
      "Train Epoch: 0 [85% 300/352]\tLoss: 0.732890\tData (t) 2.024\tBatch (t) 2.064\n",
      "Train Epoch: 0 [91% 320/352]\tLoss: 0.906724\tData (t) 2.028\tBatch (t) 2.074\n",
      "Train Epoch: 0 [97% 340/352]\tLoss: 0.755277\tData (t) 2.018\tBatch (t) 2.181\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.4452   Acc: 77.66: 100% 40/40 [00:37<00:00,  1.08it/s]\n",
      "Val acc at epoch 0: 77.66\n",
      "Saving model to ./config2_1.pt\n",
      "Train Epoch: 1 [0% 0/352]\tLoss: 0.676741\tData (t) 10.397\tBatch (t) 10.759\n",
      "Train Epoch: 1 [6% 20/352]\tLoss: 0.618062\tData (t) 2.011\tBatch (t) 2.044\n",
      "Train Epoch: 1 [11% 40/352]\tLoss: 0.593301\tData (t) 2.021\tBatch (t) 2.058\n",
      "Train Epoch: 1 [17% 60/352]\tLoss: 0.638656\tData (t) 2.044\tBatch (t) 2.076\n",
      "Train Epoch: 1 [23% 80/352]\tLoss: 0.661722\tData (t) 2.043\tBatch (t) 2.075\n",
      "Train Epoch: 1 [28% 100/352]\tLoss: 0.487982\tData (t) 2.011\tBatch (t) 2.042\n",
      "Train Epoch: 1 [34% 120/352]\tLoss: 0.665891\tData (t) 2.032\tBatch (t) 2.064\n",
      "Train Epoch: 1 [40% 140/352]\tLoss: 0.654861\tData (t) 2.030\tBatch (t) 2.062\n",
      "Train Epoch: 1 [45% 160/352]\tLoss: 0.617651\tData (t) 2.033\tBatch (t) 2.065\n",
      "Train Epoch: 1 [51% 180/352]\tLoss: 0.712417\tData (t) 1.885\tBatch (t) 2.126\n",
      "Train Epoch: 1 [57% 200/352]\tLoss: 0.619495\tData (t) 1.812\tBatch (t) 2.069\n",
      "Train Epoch: 1 [62% 220/352]\tLoss: 0.604688\tData (t) 1.934\tBatch (t) 1.966\n",
      "Train Epoch: 1 [68% 240/352]\tLoss: 0.830658\tData (t) 2.040\tBatch (t) 2.071\n",
      "Train Epoch: 1 [74% 260/352]\tLoss: 0.537400\tData (t) 2.030\tBatch (t) 2.062\n",
      "Train Epoch: 1 [80% 280/352]\tLoss: 0.524023\tData (t) 2.027\tBatch (t) 2.059\n",
      "Train Epoch: 1 [85% 300/352]\tLoss: 0.751732\tData (t) 2.041\tBatch (t) 2.073\n",
      "Train Epoch: 1 [91% 320/352]\tLoss: 0.612888\tData (t) 2.024\tBatch (t) 2.184\n",
      "Train Epoch: 1 [97% 340/352]\tLoss: 0.724967\tData (t) 1.871\tBatch (t) 1.903\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.9015   Acc: 79.52: 100% 40/40 [00:46<00:00,  1.17s/it]\n",
      "Val acc at epoch 1: 79.52\n",
      "Saving model to ./config2_2.pt\n",
      "Train Epoch: 2 [0% 0/352]\tLoss: 0.333616\tData (t) 12.899\tBatch (t) 13.088\n",
      "Train Epoch: 2 [6% 20/352]\tLoss: 0.301759\tData (t) 2.075\tBatch (t) 2.122\n",
      "Train Epoch: 2 [11% 40/352]\tLoss: 0.426270\tData (t) 2.023\tBatch (t) 2.055\n",
      "Train Epoch: 2 [17% 60/352]\tLoss: 0.343622\tData (t) 2.046\tBatch (t) 2.100\n",
      "Train Epoch: 2 [23% 80/352]\tLoss: 0.380778\tData (t) 1.859\tBatch (t) 2.099\n",
      "Train Epoch: 2 [28% 100/352]\tLoss: 0.334388\tData (t) 1.831\tBatch (t) 1.862\n",
      "Train Epoch: 2 [34% 120/352]\tLoss: 0.337016\tData (t) 2.029\tBatch (t) 2.061\n",
      "Train Epoch: 2 [40% 140/352]\tLoss: 0.313427\tData (t) 2.034\tBatch (t) 2.086\n",
      "Train Epoch: 2 [45% 160/352]\tLoss: 0.382062\tData (t) 2.037\tBatch (t) 2.068\n",
      "Train Epoch: 2 [51% 180/352]\tLoss: 0.260750\tData (t) 2.029\tBatch (t) 2.071\n",
      "Train Epoch: 2 [57% 200/352]\tLoss: 0.359604\tData (t) 2.034\tBatch (t) 2.076\n",
      "Train Epoch: 2 [62% 220/352]\tLoss: 0.327629\tData (t) 2.014\tBatch (t) 2.056\n",
      "Train Epoch: 2 [68% 240/352]\tLoss: 0.335867\tData (t) 2.018\tBatch (t) 2.062\n",
      "Train Epoch: 2 [74% 260/352]\tLoss: 0.236344\tData (t) 2.024\tBatch (t) 2.186\n",
      "Train Epoch: 2 [80% 280/352]\tLoss: 0.220993\tData (t) 2.010\tBatch (t) 2.052\n",
      "Train Epoch: 2 [85% 300/352]\tLoss: 0.330630\tData (t) 2.008\tBatch (t) 2.041\n",
      "Train Epoch: 2 [91% 320/352]\tLoss: 0.391981\tData (t) 2.036\tBatch (t) 2.068\n",
      "Train Epoch: 2 [97% 340/352]\tLoss: 0.246701\tData (t) 2.037\tBatch (t) 2.069\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.7784   Acc: 79.82: 100% 40/40 [00:34<00:00,  1.14it/s]\n",
      "Val acc at epoch 2: 79.82\n",
      "Saving model to ./config2_3.pt\n",
      "Train Epoch: 3 [0% 0/352]\tLoss: 0.156245\tData (t) 5.439\tBatch (t) 5.723\n",
      "Train Epoch: 3 [6% 20/352]\tLoss: 0.089623\tData (t) 2.079\tBatch (t) 2.111\n",
      "Train Epoch: 3 [11% 40/352]\tLoss: 0.157543\tData (t) 2.013\tBatch (t) 2.045\n",
      "Train Epoch: 3 [17% 60/352]\tLoss: 0.158901\tData (t) 2.048\tBatch (t) 2.079\n",
      "Train Epoch: 3 [23% 80/352]\tLoss: 0.137364\tData (t) 2.035\tBatch (t) 2.067\n",
      "Train Epoch: 3 [28% 100/352]\tLoss: 0.180458\tData (t) 2.011\tBatch (t) 2.043\n",
      "Train Epoch: 3 [34% 120/352]\tLoss: 0.148695\tData (t) 2.026\tBatch (t) 2.057\n",
      "Train Epoch: 3 [40% 140/352]\tLoss: 0.149966\tData (t) 2.030\tBatch (t) 2.074\n",
      "Train Epoch: 3 [45% 160/352]\tLoss: 0.167727\tData (t) 2.041\tBatch (t) 2.072\n",
      "Train Epoch: 3 [51% 180/352]\tLoss: 0.125779\tData (t) 2.037\tBatch (t) 2.068\n",
      "Train Epoch: 3 [57% 200/352]\tLoss: 0.102279\tData (t) 2.030\tBatch (t) 2.183\n",
      "Train Epoch: 3 [62% 220/352]\tLoss: 0.098721\tData (t) 1.871\tBatch (t) 1.901\n",
      "Train Epoch: 3 [68% 240/352]\tLoss: 0.218179\tData (t) 2.032\tBatch (t) 2.070\n",
      "Train Epoch: 3 [74% 260/352]\tLoss: 0.128042\tData (t) 2.035\tBatch (t) 2.066\n",
      "Train Epoch: 3 [80% 280/352]\tLoss: 0.130421\tData (t) 2.036\tBatch (t) 2.067\n",
      "Train Epoch: 3 [85% 300/352]\tLoss: 0.137891\tData (t) 1.825\tBatch (t) 1.858\n",
      "Train Epoch: 3 [91% 320/352]\tLoss: 0.187173\tData (t) 1.876\tBatch (t) 2.101\n",
      "Train Epoch: 3 [97% 340/352]\tLoss: 0.171679\tData (t) 2.038\tBatch (t) 2.070\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.6679   Acc: 80.09: 100% 40/40 [00:34<00:00,  1.15it/s]\n",
      "Val acc at epoch 3: 80.09\n",
      "Saving model to ./config2_4.pt\n",
      "Train Epoch: 4 [0% 0/352]\tLoss: 0.027313\tData (t) 7.738\tBatch (t) 7.974\n",
      "Train Epoch: 4 [6% 20/352]\tLoss: 0.067287\tData (t) 2.049\tBatch (t) 2.097\n",
      "Train Epoch: 4 [11% 40/352]\tLoss: 0.075789\tData (t) 2.000\tBatch (t) 2.031\n",
      "Train Epoch: 4 [17% 60/352]\tLoss: 0.080053\tData (t) 2.031\tBatch (t) 2.084\n",
      "Train Epoch: 4 [23% 80/352]\tLoss: 0.071117\tData (t) 2.029\tBatch (t) 2.079\n",
      "Train Epoch: 4 [28% 100/352]\tLoss: 0.047882\tData (t) 2.024\tBatch (t) 2.064\n",
      "Train Epoch: 4 [34% 120/352]\tLoss: 0.039832\tData (t) 2.021\tBatch (t) 2.059\n",
      "Train Epoch: 4 [40% 140/352]\tLoss: 0.067026\tData (t) 1.823\tBatch (t) 2.044\n",
      "Train Epoch: 4 [45% 160/352]\tLoss: 0.058693\tData (t) 1.945\tBatch (t) 1.997\n",
      "Train Epoch: 4 [51% 180/352]\tLoss: 0.100054\tData (t) 2.032\tBatch (t) 2.063\n",
      "Train Epoch: 4 [57% 200/352]\tLoss: 0.074906\tData (t) 2.042\tBatch (t) 2.073\n",
      "Train Epoch: 4 [62% 220/352]\tLoss: 0.051781\tData (t) 2.043\tBatch (t) 2.075\n",
      "Train Epoch: 4 [68% 240/352]\tLoss: 0.059039\tData (t) 2.039\tBatch (t) 2.071\n",
      "Train Epoch: 4 [74% 260/352]\tLoss: 0.049112\tData (t) 2.034\tBatch (t) 2.066\n",
      "Train Epoch: 4 [80% 280/352]\tLoss: 0.095064\tData (t) 2.036\tBatch (t) 2.067\n",
      "Train Epoch: 4 [85% 300/352]\tLoss: 0.042868\tData (t) 2.040\tBatch (t) 2.071\n",
      "Train Epoch: 4 [91% 320/352]\tLoss: 0.038207\tData (t) 2.040\tBatch (t) 2.072\n",
      "Train Epoch: 4 [97% 340/352]\tLoss: 0.042428\tData (t) 2.043\tBatch (t) 2.074\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.5973   Acc: 81.02: 100% 40/40 [00:33<00:00,  1.20it/s]\n",
      "Val acc at epoch 4: 81.02\n",
      "Saving model to ./config2_5.pt\n",
      "Train Epoch: 5 [0% 0/352]\tLoss: 0.064929\tData (t) 7.615\tBatch (t) 7.874\n",
      "Train Epoch: 5 [6% 20/352]\tLoss: 0.011683\tData (t) 2.089\tBatch (t) 2.120\n",
      "Train Epoch: 5 [11% 40/352]\tLoss: 0.024168\tData (t) 2.014\tBatch (t) 2.050\n",
      "Train Epoch: 5 [17% 60/352]\tLoss: 0.026901\tData (t) 2.054\tBatch (t) 2.084\n",
      "Train Epoch: 5 [23% 80/352]\tLoss: 0.027791\tData (t) 2.034\tBatch (t) 2.065\n",
      "Train Epoch: 5 [28% 100/352]\tLoss: 0.019660\tData (t) 2.043\tBatch (t) 2.074\n",
      "Train Epoch: 5 [34% 120/352]\tLoss: 0.023394\tData (t) 2.040\tBatch (t) 2.071\n",
      "Train Epoch: 5 [40% 140/352]\tLoss: 0.040711\tData (t) 2.035\tBatch (t) 2.074\n",
      "Train Epoch: 5 [45% 160/352]\tLoss: 0.023937\tData (t) 2.041\tBatch (t) 2.072\n",
      "Train Epoch: 5 [51% 180/352]\tLoss: 0.032513\tData (t) 2.033\tBatch (t) 2.064\n",
      "Train Epoch: 5 [57% 200/352]\tLoss: 0.031272\tData (t) 2.034\tBatch (t) 2.065\n",
      "Train Epoch: 5 [62% 220/352]\tLoss: 0.015104\tData (t) 2.036\tBatch (t) 2.068\n",
      "Train Epoch: 5 [68% 240/352]\tLoss: 0.019935\tData (t) 2.041\tBatch (t) 2.072\n",
      "Train Epoch: 5 [74% 260/352]\tLoss: 0.031458\tData (t) 1.822\tBatch (t) 1.975\n",
      "Train Epoch: 5 [80% 280/352]\tLoss: 0.020223\tData (t) 1.894\tBatch (t) 2.149\n",
      "Train Epoch: 5 [85% 300/352]\tLoss: 0.011479\tData (t) 2.037\tBatch (t) 2.068\n",
      "Train Epoch: 5 [91% 320/352]\tLoss: 0.040380\tData (t) 1.802\tBatch (t) 2.099\n",
      "Train Epoch: 5 [97% 340/352]\tLoss: 0.010471\tData (t) 2.036\tBatch (t) 2.067\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.7309   Acc: 81.12: 100% 40/40 [00:41<00:00,  1.04s/it]\n",
      "Val acc at epoch 5: 81.12\n",
      "Saving model to ./config2_6.pt\n",
      "Train Epoch: 6 [0% 0/352]\tLoss: 0.009487\tData (t) 7.405\tBatch (t) 8.620\n",
      "Train Epoch: 6 [6% 20/352]\tLoss: 0.006453\tData (t) 2.063\tBatch (t) 2.096\n",
      "Train Epoch: 6 [11% 40/352]\tLoss: 0.008782\tData (t) 2.027\tBatch (t) 2.058\n",
      "Train Epoch: 6 [17% 60/352]\tLoss: 0.008520\tData (t) 2.048\tBatch (t) 2.080\n",
      "Train Epoch: 6 [23% 80/352]\tLoss: 0.004801\tData (t) 2.036\tBatch (t) 2.068\n",
      "Train Epoch: 6 [28% 100/352]\tLoss: 0.011488\tData (t) 2.022\tBatch (t) 2.061\n",
      "Train Epoch: 6 [34% 120/352]\tLoss: 0.010120\tData (t) 2.027\tBatch (t) 2.059\n",
      "Train Epoch: 6 [40% 140/352]\tLoss: 0.013234\tData (t) 2.042\tBatch (t) 2.074\n",
      "Train Epoch: 6 [45% 160/352]\tLoss: 0.007728\tData (t) 2.043\tBatch (t) 2.075\n",
      "Train Epoch: 6 [51% 180/352]\tLoss: 0.011475\tData (t) 2.039\tBatch (t) 2.072\n",
      "Train Epoch: 6 [57% 200/352]\tLoss: 0.006148\tData (t) 2.038\tBatch (t) 2.069\n",
      "Train Epoch: 6 [62% 220/352]\tLoss: 0.010155\tData (t) 2.035\tBatch (t) 2.067\n",
      "Train Epoch: 6 [68% 240/352]\tLoss: 0.011376\tData (t) 1.878\tBatch (t) 2.073\n",
      "Train Epoch: 6 [74% 260/352]\tLoss: 0.006646\tData (t) 2.036\tBatch (t) 2.067\n",
      "Train Epoch: 6 [80% 280/352]\tLoss: 0.007011\tData (t) 2.038\tBatch (t) 2.070\n",
      "Train Epoch: 6 [85% 300/352]\tLoss: 0.005530\tData (t) 2.035\tBatch (t) 2.085\n",
      "Train Epoch: 6 [91% 320/352]\tLoss: 0.007036\tData (t) 2.021\tBatch (t) 2.069\n",
      "Train Epoch: 6 [97% 340/352]\tLoss: 0.005386\tData (t) 2.030\tBatch (t) 2.061\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.6725   Acc: 81.87: 100% 40/40 [00:37<00:00,  1.07it/s]\n",
      "Val acc at epoch 6: 81.87\n",
      "Saving model to ./config2_7.pt\n",
      "Train Epoch: 7 [0% 0/352]\tLoss: 0.001847\tData (t) 6.603\tBatch (t) 6.938\n",
      "Train Epoch: 7 [6% 20/352]\tLoss: 0.002920\tData (t) 2.079\tBatch (t) 2.110\n",
      "Train Epoch: 7 [11% 40/352]\tLoss: 0.001780\tData (t) 2.012\tBatch (t) 2.043\n",
      "Train Epoch: 7 [17% 60/352]\tLoss: 0.001361\tData (t) 2.048\tBatch (t) 2.080\n",
      "Train Epoch: 7 [23% 80/352]\tLoss: 0.002550\tData (t) 2.036\tBatch (t) 2.067\n",
      "Train Epoch: 7 [28% 100/352]\tLoss: 0.002099\tData (t) 2.002\tBatch (t) 2.033\n",
      "Train Epoch: 7 [34% 120/352]\tLoss: 0.002073\tData (t) 2.013\tBatch (t) 2.044\n",
      "Train Epoch: 7 [40% 140/352]\tLoss: 0.001184\tData (t) 2.025\tBatch (t) 2.056\n",
      "Train Epoch: 7 [45% 160/352]\tLoss: 0.002236\tData (t) 2.034\tBatch (t) 2.066\n",
      "Train Epoch: 7 [51% 180/352]\tLoss: 0.001135\tData (t) 2.009\tBatch (t) 2.071\n",
      "Train Epoch: 7 [57% 200/352]\tLoss: 0.024861\tData (t) 2.037\tBatch (t) 2.083\n",
      "Train Epoch: 7 [62% 220/352]\tLoss: 0.029999\tData (t) 2.028\tBatch (t) 2.069\n",
      "Train Epoch: 7 [68% 240/352]\tLoss: 0.001408\tData (t) 1.795\tBatch (t) 2.082\n",
      "Train Epoch: 7 [74% 260/352]\tLoss: 0.001177\tData (t) 1.783\tBatch (t) 2.070\n",
      "Train Epoch: 7 [80% 280/352]\tLoss: 0.002928\tData (t) 1.881\tBatch (t) 2.160\n",
      "Train Epoch: 7 [85% 300/352]\tLoss: 0.002807\tData (t) 1.762\tBatch (t) 2.071\n",
      "Train Epoch: 7 [91% 320/352]\tLoss: 0.001812\tData (t) 2.039\tBatch (t) 2.070\n",
      "Train Epoch: 7 [97% 340/352]\tLoss: 0.002144\tData (t) 2.037\tBatch (t) 2.231\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.4866   Acc: 82.28: 100% 40/40 [00:37<00:00,  1.07it/s]\n",
      "Val acc at epoch 7: 82.28\n",
      "Saving model to ./config2_8.pt\n",
      "Train Epoch: 8 [0% 0/352]\tLoss: 0.000661\tData (t) 4.658\tBatch (t) 4.794\n",
      "Train Epoch: 8 [6% 20/352]\tLoss: 0.000775\tData (t) 2.079\tBatch (t) 2.110\n",
      "Train Epoch: 8 [11% 40/352]\tLoss: 0.000645\tData (t) 2.015\tBatch (t) 2.048\n",
      "Train Epoch: 8 [17% 60/352]\tLoss: 0.000680\tData (t) 2.050\tBatch (t) 2.083\n",
      "Train Epoch: 8 [23% 80/352]\tLoss: 0.000674\tData (t) 1.831\tBatch (t) 1.863\n",
      "Train Epoch: 8 [28% 100/352]\tLoss: 0.000493\tData (t) 1.869\tBatch (t) 1.905\n",
      "Train Epoch: 8 [34% 120/352]\tLoss: 0.000482\tData (t) 2.036\tBatch (t) 2.070\n",
      "Train Epoch: 8 [40% 140/352]\tLoss: 0.000669\tData (t) 2.039\tBatch (t) 2.074\n",
      "Train Epoch: 8 [45% 160/352]\tLoss: 0.000686\tData (t) 2.041\tBatch (t) 2.072\n",
      "Train Epoch: 8 [51% 180/352]\tLoss: 0.000463\tData (t) 2.037\tBatch (t) 2.068\n",
      "Train Epoch: 8 [57% 200/352]\tLoss: 0.000487\tData (t) 1.859\tBatch (t) 2.066\n",
      "Train Epoch: 8 [62% 220/352]\tLoss: 0.000578\tData (t) 1.898\tBatch (t) 2.080\n",
      "Train Epoch: 8 [68% 240/352]\tLoss: 0.000505\tData (t) 1.875\tBatch (t) 2.066\n",
      "Train Epoch: 8 [74% 260/352]\tLoss: 0.015455\tData (t) 1.883\tBatch (t) 2.069\n",
      "Train Epoch: 8 [80% 280/352]\tLoss: 0.000692\tData (t) 2.018\tBatch (t) 2.049\n",
      "Train Epoch: 8 [85% 300/352]\tLoss: 0.000498\tData (t) 2.036\tBatch (t) 2.067\n",
      "Train Epoch: 8 [91% 320/352]\tLoss: 0.000403\tData (t) 2.037\tBatch (t) 2.069\n",
      "Train Epoch: 8 [97% 340/352]\tLoss: 0.000839\tData (t) 2.021\tBatch (t) 2.216\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.4982   Acc: 82.53: 100% 40/40 [00:40<00:00,  1.02s/it]\n",
      "Val acc at epoch 8: 82.53\n",
      "Saving model to ./config2_9.pt\n",
      "Train Epoch: 9 [0% 0/352]\tLoss: 0.000526\tData (t) 10.155\tBatch (t) 11.574\n",
      "Train Epoch: 9 [6% 20/352]\tLoss: 0.000433\tData (t) 1.839\tBatch (t) 2.170\n",
      "Train Epoch: 9 [11% 40/352]\tLoss: 0.000427\tData (t) 1.739\tBatch (t) 2.090\n",
      "Train Epoch: 9 [17% 60/352]\tLoss: 0.000503\tData (t) 1.879\tBatch (t) 2.202\n",
      "Train Epoch: 9 [23% 80/352]\tLoss: 0.000438\tData (t) 1.879\tBatch (t) 2.174\n",
      "Train Epoch: 9 [28% 100/352]\tLoss: 0.000533\tData (t) 1.875\tBatch (t) 2.086\n",
      "Train Epoch: 9 [34% 120/352]\tLoss: 0.000447\tData (t) 2.032\tBatch (t) 2.226\n",
      "Train Epoch: 9 [40% 140/352]\tLoss: 0.000523\tData (t) 2.040\tBatch (t) 2.071\n",
      "Train Epoch: 9 [45% 160/352]\tLoss: 0.000362\tData (t) 2.036\tBatch (t) 2.068\n",
      "Train Epoch: 9 [51% 180/352]\tLoss: 0.000464\tData (t) 2.036\tBatch (t) 2.068\n",
      "Train Epoch: 9 [57% 200/352]\tLoss: 0.000426\tData (t) 2.035\tBatch (t) 2.075\n",
      "Train Epoch: 9 [62% 220/352]\tLoss: 0.000664\tData (t) 1.999\tBatch (t) 2.032\n",
      "Train Epoch: 9 [68% 240/352]\tLoss: 0.000505\tData (t) 2.015\tBatch (t) 2.048\n",
      "Train Epoch: 9 [74% 260/352]\tLoss: 0.000504\tData (t) 2.013\tBatch (t) 2.044\n",
      "Train Epoch: 9 [80% 280/352]\tLoss: 0.000466\tData (t) 2.025\tBatch (t) 2.056\n",
      "Train Epoch: 9 [85% 300/352]\tLoss: 0.000559\tData (t) 2.013\tBatch (t) 2.044\n",
      "Train Epoch: 9 [91% 320/352]\tLoss: 0.000442\tData (t) 2.020\tBatch (t) 2.066\n",
      "Train Epoch: 9 [97% 340/352]\tLoss: 0.000584\tData (t) 2.020\tBatch (t) 2.067\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.4952   Acc: 82.58: 100% 40/40 [00:34<00:00,  1.15it/s]\n",
      "Val acc at epoch 9: 82.58\n",
      "Saving model to ./config2_10.pt\n",
      "✅ Configuration 2 completed and backed up to Drive!\n"
     ]
    }
   ],
   "source": [
    "# Configuration 2: lr=1e-5, wd=0.1, epochs=10, batch_size=256, timm_aug=False\n",
    "!python $CODE_DIR/finetune.py --lr 1e-5 --wd 0.1 --epochs 10 --batch-size 256 --data-location $DATA_DIR --name \"config2\"\n",
    "\n",
    "# Backup model to Google Drive\n",
    "!cp config2_*.pt \"/content/drive/MyDrive/Colab Notebooks/\"\n",
    "print(\"✅ Configuration 2 completed and backed up to Drive!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8116508,
     "status": "ok",
     "timestamp": 1755944146032,
     "user": {
      "displayName": "Yang Zhou",
      "userId": "09717432835810465973"
     },
     "user_tz": 240
    },
    "id": "Z8Qw_Tl0kQFE",
    "outputId": "159f3a80-a697-4829-84ec-0fca8d37dc18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Building zero-shot classifier.\n",
      "100% 200/200 [00:11<00:00, 17.26it/s]\n",
      "Saving model to ./config3_0.pt\n",
      "Train Epoch: 0 [0% 0/352]\tLoss: 1.600170\tData (t) 10.423\tBatch (t) 17.322\n",
      "Train Epoch: 0 [6% 20/352]\tLoss: 1.583610\tData (t) 2.006\tBatch (t) 2.053\n",
      "Train Epoch: 0 [11% 40/352]\tLoss: 1.211902\tData (t) 2.009\tBatch (t) 2.065\n",
      "Train Epoch: 0 [17% 60/352]\tLoss: 1.175887\tData (t) 2.009\tBatch (t) 2.053\n",
      "Train Epoch: 0 [23% 80/352]\tLoss: 1.156675\tData (t) 2.027\tBatch (t) 2.253\n",
      "Train Epoch: 0 [28% 100/352]\tLoss: 1.083810\tData (t) 2.030\tBatch (t) 2.061\n",
      "Train Epoch: 0 [34% 120/352]\tLoss: 1.012528\tData (t) 2.031\tBatch (t) 2.299\n",
      "Train Epoch: 0 [40% 140/352]\tLoss: 1.187462\tData (t) 2.035\tBatch (t) 2.067\n",
      "Train Epoch: 0 [45% 160/352]\tLoss: 0.988308\tData (t) 2.035\tBatch (t) 2.067\n",
      "Train Epoch: 0 [51% 180/352]\tLoss: 1.009607\tData (t) 2.036\tBatch (t) 2.069\n",
      "Train Epoch: 0 [57% 200/352]\tLoss: 0.782348\tData (t) 2.033\tBatch (t) 2.064\n",
      "Train Epoch: 0 [62% 220/352]\tLoss: 1.010485\tData (t) 2.034\tBatch (t) 2.070\n",
      "Train Epoch: 0 [68% 240/352]\tLoss: 1.001990\tData (t) 2.030\tBatch (t) 2.061\n",
      "Train Epoch: 0 [74% 260/352]\tLoss: 1.088537\tData (t) 2.030\tBatch (t) 2.061\n",
      "Train Epoch: 0 [80% 280/352]\tLoss: 0.921718\tData (t) 2.036\tBatch (t) 2.080\n",
      "Train Epoch: 0 [85% 300/352]\tLoss: 0.892968\tData (t) 2.033\tBatch (t) 2.083\n",
      "Train Epoch: 0 [91% 320/352]\tLoss: 1.035184\tData (t) 2.019\tBatch (t) 2.060\n",
      "Train Epoch: 0 [97% 340/352]\tLoss: 0.890812\tData (t) 2.030\tBatch (t) 2.085\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.6565   Acc: 75.94: 100% 40/40 [00:41<00:00,  1.04s/it]\n",
      "Val acc at epoch 0: 75.94\n",
      "Saving model to ./config3_1.pt\n",
      "Train Epoch: 1 [0% 0/352]\tLoss: 0.662339\tData (t) 6.326\tBatch (t) 8.210\n",
      "Train Epoch: 1 [6% 20/352]\tLoss: 0.876097\tData (t) 1.776\tBatch (t) 2.036\n",
      "Train Epoch: 1 [11% 40/352]\tLoss: 0.792482\tData (t) 1.829\tBatch (t) 2.075\n",
      "Train Epoch: 1 [17% 60/352]\tLoss: 0.698151\tData (t) 2.021\tBatch (t) 2.053\n",
      "Train Epoch: 1 [23% 80/352]\tLoss: 0.829791\tData (t) 2.035\tBatch (t) 2.270\n",
      "Train Epoch: 1 [28% 100/352]\tLoss: 0.805837\tData (t) 1.808\tBatch (t) 1.840\n",
      "Train Epoch: 1 [34% 120/352]\tLoss: 0.722317\tData (t) 2.033\tBatch (t) 2.064\n",
      "Train Epoch: 1 [40% 140/352]\tLoss: 0.606036\tData (t) 2.032\tBatch (t) 2.063\n",
      "Train Epoch: 1 [45% 160/352]\tLoss: 0.829132\tData (t) 2.030\tBatch (t) 2.064\n",
      "Train Epoch: 1 [51% 180/352]\tLoss: 0.668275\tData (t) 2.035\tBatch (t) 2.069\n",
      "Train Epoch: 1 [57% 200/352]\tLoss: 0.805247\tData (t) 2.040\tBatch (t) 2.071\n",
      "Train Epoch: 1 [62% 220/352]\tLoss: 0.734003\tData (t) 1.944\tBatch (t) 2.138\n",
      "Train Epoch: 1 [68% 240/352]\tLoss: 0.647663\tData (t) 1.873\tBatch (t) 2.081\n",
      "Train Epoch: 1 [74% 260/352]\tLoss: 0.741500\tData (t) 1.865\tBatch (t) 2.063\n",
      "Train Epoch: 1 [80% 280/352]\tLoss: 0.784309\tData (t) 2.036\tBatch (t) 2.246\n",
      "Train Epoch: 1 [85% 300/352]\tLoss: 0.762425\tData (t) 2.031\tBatch (t) 2.062\n",
      "Train Epoch: 1 [91% 320/352]\tLoss: 0.716615\tData (t) 2.029\tBatch (t) 2.061\n",
      "Train Epoch: 1 [97% 340/352]\tLoss: 0.665906\tData (t) 2.038\tBatch (t) 2.080\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.3520   Acc: 79.38: 100% 40/40 [00:35<00:00,  1.12it/s]\n",
      "Val acc at epoch 1: 79.38\n",
      "Saving model to ./config3_2.pt\n",
      "Train Epoch: 2 [0% 0/352]\tLoss: 0.500475\tData (t) 5.105\tBatch (t) 6.620\n",
      "Train Epoch: 2 [6% 20/352]\tLoss: 0.474187\tData (t) 2.046\tBatch (t) 2.077\n",
      "Train Epoch: 2 [11% 40/352]\tLoss: 0.465886\tData (t) 2.027\tBatch (t) 2.059\n",
      "Train Epoch: 2 [17% 60/352]\tLoss: 0.514993\tData (t) 2.040\tBatch (t) 2.075\n",
      "Train Epoch: 2 [23% 80/352]\tLoss: 0.456437\tData (t) 2.016\tBatch (t) 2.051\n",
      "Train Epoch: 2 [28% 100/352]\tLoss: 0.582185\tData (t) 2.032\tBatch (t) 2.230\n",
      "Train Epoch: 2 [34% 120/352]\tLoss: 0.607842\tData (t) 1.883\tBatch (t) 1.915\n",
      "Train Epoch: 2 [40% 140/352]\tLoss: 0.470312\tData (t) 2.037\tBatch (t) 2.069\n",
      "Train Epoch: 2 [45% 160/352]\tLoss: 0.590207\tData (t) 2.035\tBatch (t) 2.067\n",
      "Train Epoch: 2 [51% 180/352]\tLoss: 0.493021\tData (t) 2.035\tBatch (t) 2.067\n",
      "Train Epoch: 2 [57% 200/352]\tLoss: 0.451906\tData (t) 2.033\tBatch (t) 2.065\n",
      "Train Epoch: 2 [62% 220/352]\tLoss: 0.444617\tData (t) 2.031\tBatch (t) 2.228\n",
      "Train Epoch: 2 [68% 240/352]\tLoss: 0.466867\tData (t) 2.032\tBatch (t) 2.063\n",
      "Train Epoch: 2 [74% 260/352]\tLoss: 0.373290\tData (t) 2.033\tBatch (t) 2.066\n",
      "Train Epoch: 2 [80% 280/352]\tLoss: 0.384304\tData (t) 2.026\tBatch (t) 2.057\n",
      "Train Epoch: 2 [85% 300/352]\tLoss: 0.410113\tData (t) 2.031\tBatch (t) 2.067\n",
      "Train Epoch: 2 [91% 320/352]\tLoss: 0.537159\tData (t) 2.037\tBatch (t) 2.069\n",
      "Train Epoch: 2 [97% 340/352]\tLoss: 0.390819\tData (t) 2.033\tBatch (t) 2.065\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.2622   Acc: 80.01: 100% 40/40 [00:36<00:00,  1.10it/s]\n",
      "Val acc at epoch 2: 80.01\n",
      "Saving model to ./config3_3.pt\n",
      "Train Epoch: 3 [0% 0/352]\tLoss: 0.241235\tData (t) 7.409\tBatch (t) 7.734\n",
      "Train Epoch: 3 [6% 20/352]\tLoss: 0.179509\tData (t) 1.890\tBatch (t) 1.922\n",
      "Train Epoch: 3 [11% 40/352]\tLoss: 0.203018\tData (t) 2.013\tBatch (t) 2.044\n",
      "Train Epoch: 3 [17% 60/352]\tLoss: 0.234291\tData (t) 2.042\tBatch (t) 2.073\n",
      "Train Epoch: 3 [23% 80/352]\tLoss: 0.268600\tData (t) 1.780\tBatch (t) 1.968\n",
      "Train Epoch: 3 [28% 100/352]\tLoss: 0.246853\tData (t) 1.784\tBatch (t) 2.110\n",
      "Train Epoch: 3 [34% 120/352]\tLoss: 0.251016\tData (t) 1.692\tBatch (t) 1.760\n",
      "Train Epoch: 3 [40% 140/352]\tLoss: 0.296930\tData (t) 1.788\tBatch (t) 2.233\n",
      "Train Epoch: 3 [45% 160/352]\tLoss: 0.252995\tData (t) 1.658\tBatch (t) 2.033\n",
      "Train Epoch: 3 [51% 180/352]\tLoss: 0.305707\tData (t) 1.760\tBatch (t) 1.813\n",
      "Train Epoch: 3 [57% 200/352]\tLoss: 0.306189\tData (t) 1.788\tBatch (t) 2.074\n",
      "Train Epoch: 3 [62% 220/352]\tLoss: 0.350857\tData (t) 1.843\tBatch (t) 1.993\n",
      "Train Epoch: 3 [68% 240/352]\tLoss: 0.191904\tData (t) 2.026\tBatch (t) 2.058\n",
      "Train Epoch: 3 [74% 260/352]\tLoss: 0.233573\tData (t) 1.820\tBatch (t) 2.031\n",
      "Train Epoch: 3 [80% 280/352]\tLoss: 0.167820\tData (t) 1.847\tBatch (t) 1.878\n",
      "Train Epoch: 3 [85% 300/352]\tLoss: 0.250414\tData (t) 2.030\tBatch (t) 2.062\n",
      "Train Epoch: 3 [91% 320/352]\tLoss: 0.258587\tData (t) 2.028\tBatch (t) 2.221\n",
      "Train Epoch: 3 [97% 340/352]\tLoss: 0.209613\tData (t) 2.037\tBatch (t) 2.071\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.0777   Acc: 80.33: 100% 40/40 [00:38<00:00,  1.04it/s]\n",
      "Val acc at epoch 3: 80.33\n",
      "Saving model to ./config3_4.pt\n",
      "Train Epoch: 4 [0% 0/352]\tLoss: 0.124026\tData (t) 8.745\tBatch (t) 9.094\n",
      "Train Epoch: 4 [6% 20/352]\tLoss: 0.144066\tData (t) 1.898\tBatch (t) 2.076\n",
      "Train Epoch: 4 [11% 40/352]\tLoss: 0.145167\tData (t) 1.813\tBatch (t) 1.914\n",
      "Train Epoch: 4 [17% 60/352]\tLoss: 0.089334\tData (t) 2.042\tBatch (t) 2.073\n",
      "Train Epoch: 4 [23% 80/352]\tLoss: 0.151503\tData (t) 2.033\tBatch (t) 2.067\n",
      "Train Epoch: 4 [28% 100/352]\tLoss: 0.146599\tData (t) 1.736\tBatch (t) 2.061\n",
      "Train Epoch: 4 [34% 120/352]\tLoss: 0.071482\tData (t) 2.012\tBatch (t) 2.045\n",
      "Train Epoch: 4 [40% 140/352]\tLoss: 0.127730\tData (t) 1.997\tBatch (t) 2.039\n",
      "Train Epoch: 4 [45% 160/352]\tLoss: 0.157282\tData (t) 2.036\tBatch (t) 2.068\n",
      "Train Epoch: 4 [51% 180/352]\tLoss: 0.104406\tData (t) 2.039\tBatch (t) 2.071\n",
      "Train Epoch: 4 [57% 200/352]\tLoss: 0.126441\tData (t) 2.036\tBatch (t) 2.068\n",
      "Train Epoch: 4 [62% 220/352]\tLoss: 0.109649\tData (t) 2.035\tBatch (t) 2.067\n",
      "Train Epoch: 4 [68% 240/352]\tLoss: 0.104584\tData (t) 2.035\tBatch (t) 2.066\n",
      "Train Epoch: 4 [74% 260/352]\tLoss: 0.135807\tData (t) 2.033\tBatch (t) 2.231\n",
      "Train Epoch: 4 [80% 280/352]\tLoss: 0.091511\tData (t) 2.028\tBatch (t) 2.061\n",
      "Train Epoch: 4 [85% 300/352]\tLoss: 0.100324\tData (t) 2.033\tBatch (t) 2.066\n",
      "Train Epoch: 4 [91% 320/352]\tLoss: 0.113708\tData (t) 2.042\tBatch (t) 2.073\n",
      "Train Epoch: 4 [97% 340/352]\tLoss: 0.115919\tData (t) 2.035\tBatch (t) 2.065\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.1246   Acc: 80.18: 100% 40/40 [00:43<00:00,  1.08s/it]\n",
      "Val acc at epoch 4: 80.18\n",
      "Saving model to ./config3_5.pt\n",
      "Train Epoch: 5 [0% 0/352]\tLoss: 0.104155\tData (t) 7.850\tBatch (t) 8.153\n",
      "Train Epoch: 5 [6% 20/352]\tLoss: 0.043968\tData (t) 1.870\tBatch (t) 1.901\n",
      "Train Epoch: 5 [11% 40/352]\tLoss: 0.076776\tData (t) 1.759\tBatch (t) 1.808\n",
      "Train Epoch: 5 [17% 60/352]\tLoss: 0.040138\tData (t) 1.865\tBatch (t) 2.067\n",
      "Train Epoch: 5 [23% 80/352]\tLoss: 0.046903\tData (t) 1.844\tBatch (t) 2.068\n",
      "Train Epoch: 5 [28% 100/352]\tLoss: 0.055030\tData (t) 1.834\tBatch (t) 2.140\n",
      "Train Epoch: 5 [34% 120/352]\tLoss: 0.042777\tData (t) 1.852\tBatch (t) 1.990\n",
      "Train Epoch: 5 [40% 140/352]\tLoss: 0.050542\tData (t) 1.803\tBatch (t) 1.923\n",
      "Train Epoch: 5 [45% 160/352]\tLoss: 0.029099\tData (t) 2.036\tBatch (t) 2.068\n",
      "Train Epoch: 5 [51% 180/352]\tLoss: 0.064202\tData (t) 2.034\tBatch (t) 2.234\n",
      "Train Epoch: 5 [57% 200/352]\tLoss: 0.065058\tData (t) 2.033\tBatch (t) 2.064\n",
      "Train Epoch: 5 [62% 220/352]\tLoss: 0.063958\tData (t) 2.033\tBatch (t) 2.064\n",
      "Train Epoch: 5 [68% 240/352]\tLoss: 0.050617\tData (t) 2.036\tBatch (t) 2.069\n",
      "Train Epoch: 5 [74% 260/352]\tLoss: 0.079222\tData (t) 1.881\tBatch (t) 2.082\n",
      "Train Epoch: 5 [80% 280/352]\tLoss: 0.037005\tData (t) 2.039\tBatch (t) 2.070\n",
      "Train Epoch: 5 [85% 300/352]\tLoss: 0.069549\tData (t) 2.038\tBatch (t) 2.232\n",
      "Train Epoch: 5 [91% 320/352]\tLoss: 0.036139\tData (t) 2.037\tBatch (t) 2.068\n",
      "Train Epoch: 5 [97% 340/352]\tLoss: 0.037980\tData (t) 2.042\tBatch (t) 2.073\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.2523   Acc: 79.90: 100% 40/40 [00:40<00:00,  1.01s/it]\n",
      "Val acc at epoch 5: 79.90\n",
      "Saving model to ./config3_6.pt\n",
      "Train Epoch: 6 [0% 0/352]\tLoss: 0.017797\tData (t) 7.258\tBatch (t) 9.325\n",
      "Train Epoch: 6 [6% 20/352]\tLoss: 0.019833\tData (t) 1.919\tBatch (t) 2.001\n",
      "Train Epoch: 6 [11% 40/352]\tLoss: 0.020508\tData (t) 1.684\tBatch (t) 1.886\n",
      "Train Epoch: 6 [17% 60/352]\tLoss: 0.016267\tData (t) 1.851\tBatch (t) 2.110\n",
      "Train Epoch: 6 [23% 80/352]\tLoss: 0.031979\tData (t) 2.031\tBatch (t) 2.062\n",
      "Train Epoch: 6 [28% 100/352]\tLoss: 0.017781\tData (t) 2.035\tBatch (t) 2.066\n",
      "Train Epoch: 6 [34% 120/352]\tLoss: 0.014045\tData (t) 2.034\tBatch (t) 2.066\n",
      "Train Epoch: 6 [40% 140/352]\tLoss: 0.020653\tData (t) 2.040\tBatch (t) 2.073\n",
      "Train Epoch: 6 [45% 160/352]\tLoss: 0.019573\tData (t) 2.028\tBatch (t) 2.059\n",
      "Train Epoch: 6 [51% 180/352]\tLoss: 0.032023\tData (t) 1.842\tBatch (t) 2.067\n",
      "Train Epoch: 6 [57% 200/352]\tLoss: 0.019799\tData (t) 1.892\tBatch (t) 2.117\n",
      "Train Epoch: 6 [62% 220/352]\tLoss: 0.041664\tData (t) 1.863\tBatch (t) 1.894\n",
      "Train Epoch: 6 [68% 240/352]\tLoss: 0.014838\tData (t) 2.040\tBatch (t) 2.071\n",
      "Train Epoch: 6 [74% 260/352]\tLoss: 0.023943\tData (t) 2.032\tBatch (t) 2.065\n",
      "Train Epoch: 6 [80% 280/352]\tLoss: 0.030169\tData (t) 2.032\tBatch (t) 2.063\n",
      "Train Epoch: 6 [85% 300/352]\tLoss: 0.017972\tData (t) 2.037\tBatch (t) 2.068\n",
      "Train Epoch: 6 [91% 320/352]\tLoss: 0.030007\tData (t) 2.035\tBatch (t) 2.067\n",
      "Train Epoch: 6 [97% 340/352]\tLoss: 0.018398\tData (t) 2.031\tBatch (t) 2.063\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.1844   Acc: 80.05: 100% 40/40 [00:35<00:00,  1.13it/s]\n",
      "Val acc at epoch 6: 80.05\n",
      "Saving model to ./config3_7.pt\n",
      "Train Epoch: 7 [0% 0/352]\tLoss: 0.008856\tData (t) 5.699\tBatch (t) 7.239\n",
      "Train Epoch: 7 [6% 20/352]\tLoss: 0.014491\tData (t) 1.848\tBatch (t) 2.105\n",
      "Train Epoch: 7 [11% 40/352]\tLoss: 0.017048\tData (t) 2.006\tBatch (t) 2.263\n",
      "Train Epoch: 7 [17% 60/352]\tLoss: 0.011247\tData (t) 2.051\tBatch (t) 2.092\n",
      "Train Epoch: 7 [23% 80/352]\tLoss: 0.007947\tData (t) 2.024\tBatch (t) 2.068\n",
      "Train Epoch: 7 [28% 100/352]\tLoss: 0.008474\tData (t) 1.875\tBatch (t) 2.018\n",
      "Train Epoch: 7 [34% 120/352]\tLoss: 0.008753\tData (t) 2.014\tBatch (t) 2.078\n",
      "Train Epoch: 7 [40% 140/352]\tLoss: 0.017390\tData (t) 2.016\tBatch (t) 2.051\n",
      "Train Epoch: 7 [45% 160/352]\tLoss: 0.009840\tData (t) 2.013\tBatch (t) 2.044\n",
      "Train Epoch: 7 [51% 180/352]\tLoss: 0.012144\tData (t) 2.024\tBatch (t) 2.055\n",
      "Train Epoch: 7 [57% 200/352]\tLoss: 0.015943\tData (t) 2.036\tBatch (t) 2.069\n",
      "Train Epoch: 7 [62% 220/352]\tLoss: 0.011105\tData (t) 2.013\tBatch (t) 2.065\n",
      "Train Epoch: 7 [68% 240/352]\tLoss: 0.007119\tData (t) 2.034\tBatch (t) 2.067\n",
      "Train Epoch: 7 [74% 260/352]\tLoss: 0.008718\tData (t) 2.037\tBatch (t) 2.068\n",
      "Train Epoch: 7 [80% 280/352]\tLoss: 0.027433\tData (t) 1.875\tBatch (t) 1.907\n",
      "Train Epoch: 7 [85% 300/352]\tLoss: 0.005524\tData (t) 2.043\tBatch (t) 2.074\n",
      "Train Epoch: 7 [91% 320/352]\tLoss: 0.006635\tData (t) 2.020\tBatch (t) 2.051\n",
      "Train Epoch: 7 [97% 340/352]\tLoss: 0.006588\tData (t) 2.038\tBatch (t) 2.069\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.3090   Acc: 79.67: 100% 40/40 [00:39<00:00,  1.01it/s]\n",
      "Val acc at epoch 7: 79.67\n",
      "Saving model to ./config3_8.pt\n",
      "Train Epoch: 8 [0% 0/352]\tLoss: 0.004926\tData (t) 9.231\tBatch (t) 9.485\n",
      "Train Epoch: 8 [6% 20/352]\tLoss: 0.005028\tData (t) 2.073\tBatch (t) 2.109\n",
      "Train Epoch: 8 [11% 40/352]\tLoss: 0.005412\tData (t) 1.945\tBatch (t) 1.987\n",
      "Train Epoch: 8 [17% 60/352]\tLoss: 0.004831\tData (t) 1.768\tBatch (t) 1.800\n",
      "Train Epoch: 8 [23% 80/352]\tLoss: 0.003969\tData (t) 1.730\tBatch (t) 1.774\n",
      "Train Epoch: 8 [28% 100/352]\tLoss: 0.005127\tData (t) 1.705\tBatch (t) 1.840\n",
      "Train Epoch: 8 [34% 120/352]\tLoss: 0.004951\tData (t) 1.744\tBatch (t) 1.962\n",
      "Train Epoch: 8 [40% 140/352]\tLoss: 0.008145\tData (t) 1.827\tBatch (t) 2.037\n",
      "Train Epoch: 8 [45% 160/352]\tLoss: 0.004193\tData (t) 1.879\tBatch (t) 2.115\n",
      "Train Epoch: 8 [51% 180/352]\tLoss: 0.004646\tData (t) 1.834\tBatch (t) 2.169\n",
      "Train Epoch: 8 [57% 200/352]\tLoss: 0.009706\tData (t) 1.851\tBatch (t) 2.104\n",
      "Train Epoch: 8 [62% 220/352]\tLoss: 0.005624\tData (t) 2.036\tBatch (t) 2.085\n",
      "Train Epoch: 8 [68% 240/352]\tLoss: 0.004888\tData (t) 2.038\tBatch (t) 2.096\n",
      "Train Epoch: 8 [74% 260/352]\tLoss: 0.006764\tData (t) 2.037\tBatch (t) 2.083\n",
      "Train Epoch: 8 [80% 280/352]\tLoss: 0.004942\tData (t) 2.037\tBatch (t) 2.092\n",
      "Train Epoch: 8 [85% 300/352]\tLoss: 0.004289\tData (t) 1.876\tBatch (t) 2.116\n",
      "Train Epoch: 8 [91% 320/352]\tLoss: 0.005942\tData (t) 1.781\tBatch (t) 1.841\n",
      "Train Epoch: 8 [97% 340/352]\tLoss: 0.013199\tData (t) 2.022\tBatch (t) 2.055\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.3488   Acc: 79.62: 100% 40/40 [00:39<00:00,  1.01it/s]\n",
      "Val acc at epoch 8: 79.62\n",
      "Saving model to ./config3_9.pt\n",
      "Train Epoch: 9 [0% 0/352]\tLoss: 0.004960\tData (t) 5.250\tBatch (t) 5.552\n",
      "Train Epoch: 9 [6% 20/352]\tLoss: 0.004220\tData (t) 2.083\tBatch (t) 2.114\n",
      "Train Epoch: 9 [11% 40/352]\tLoss: 0.005347\tData (t) 2.000\tBatch (t) 2.032\n",
      "Train Epoch: 9 [17% 60/352]\tLoss: 0.005048\tData (t) 1.990\tBatch (t) 2.077\n",
      "Train Epoch: 9 [23% 80/352]\tLoss: 0.007481\tData (t) 1.984\tBatch (t) 2.015\n",
      "Train Epoch: 9 [28% 100/352]\tLoss: 0.003823\tData (t) 1.804\tBatch (t) 1.845\n",
      "Train Epoch: 9 [34% 120/352]\tLoss: 0.004383\tData (t) 1.850\tBatch (t) 1.937\n",
      "Train Epoch: 9 [40% 140/352]\tLoss: 0.004129\tData (t) 1.844\tBatch (t) 2.108\n",
      "Train Epoch: 9 [45% 160/352]\tLoss: 0.003237\tData (t) 1.793\tBatch (t) 2.114\n",
      "Train Epoch: 9 [51% 180/352]\tLoss: 0.003658\tData (t) 1.830\tBatch (t) 2.180\n",
      "Train Epoch: 9 [57% 200/352]\tLoss: 0.004207\tData (t) 1.873\tBatch (t) 2.122\n",
      "Train Epoch: 9 [62% 220/352]\tLoss: 0.004571\tData (t) 1.881\tBatch (t) 2.132\n",
      "Train Epoch: 9 [68% 240/352]\tLoss: 0.004306\tData (t) 2.038\tBatch (t) 2.069\n",
      "Train Epoch: 9 [74% 260/352]\tLoss: 0.003941\tData (t) 2.033\tBatch (t) 2.095\n",
      "Train Epoch: 9 [80% 280/352]\tLoss: 0.002747\tData (t) 2.023\tBatch (t) 2.064\n",
      "Train Epoch: 9 [85% 300/352]\tLoss: 0.004346\tData (t) 2.038\tBatch (t) 2.080\n",
      "Train Epoch: 9 [91% 320/352]\tLoss: 0.004871\tData (t) 2.037\tBatch (t) 2.262\n",
      "Train Epoch: 9 [97% 340/352]\tLoss: 0.004017\tData (t) 2.037\tBatch (t) 2.082\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.3658   Acc: 79.52: 100% 40/40 [00:35<00:00,  1.14it/s]\n",
      "Val acc at epoch 9: 79.52\n",
      "Saving model to ./config3_10.pt\n",
      "✅ Configuration 3 completed and backed up to Drive!\n"
     ]
    }
   ],
   "source": [
    "# Configuration 3: lr=3e-6, wd=0.1, epochs=10, batch_size=256, timm_aug=False\n",
    "!python $CODE_DIR/finetune.py --lr 3e-6 --wd 0.1 --epochs 10 --batch-size 256 --data-location $DATA_DIR --name \"config3\"\n",
    "\n",
    "# Backup model to Google Drive\n",
    "!cp config3_*.pt \"/content/drive/MyDrive/Colab Notebooks/\"\n",
    "print(\"✅ Configuration 3 completed and backed up to Drive!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8273909,
     "status": "ok",
     "timestamp": 1755952419943,
     "user": {
      "displayName": "Yang Zhou",
      "userId": "09717432835810465973"
     },
     "user_tz": 240
    },
    "id": "QOoQJlw0tmwX",
    "outputId": "3ee05ee5-126e-4b11-c498-5409fc26d580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Building zero-shot classifier.\n",
      "100% 200/200 [00:12<00:00, 16.02it/s]\n",
      "Saving model to ./config4_0.pt\n",
      "Train Epoch: 0 [0% 0/352]\tLoss: 3.308727\tData (t) 15.836\tBatch (t) 23.652\n",
      "Train Epoch: 0 [6% 20/352]\tLoss: 2.737835\tData (t) 1.325\tBatch (t) 1.400\n",
      "Train Epoch: 0 [11% 40/352]\tLoss: 2.778366\tData (t) 1.858\tBatch (t) 2.029\n",
      "Train Epoch: 0 [17% 60/352]\tLoss: 2.296328\tData (t) 1.971\tBatch (t) 2.070\n",
      "Train Epoch: 0 [23% 80/352]\tLoss: 2.271421\tData (t) 1.982\tBatch (t) 2.036\n",
      "Train Epoch: 0 [28% 100/352]\tLoss: 2.170868\tData (t) 2.007\tBatch (t) 2.054\n",
      "Train Epoch: 0 [34% 120/352]\tLoss: 2.146047\tData (t) 1.986\tBatch (t) 2.038\n",
      "Train Epoch: 0 [40% 140/352]\tLoss: 1.899604\tData (t) 1.807\tBatch (t) 1.855\n",
      "Train Epoch: 0 [45% 160/352]\tLoss: 2.142196\tData (t) 1.999\tBatch (t) 2.049\n",
      "Train Epoch: 0 [51% 180/352]\tLoss: 2.240858\tData (t) 1.990\tBatch (t) 2.039\n",
      "Train Epoch: 0 [57% 200/352]\tLoss: 2.136600\tData (t) 1.904\tBatch (t) 1.955\n",
      "Train Epoch: 0 [62% 220/352]\tLoss: 2.052347\tData (t) 1.987\tBatch (t) 2.036\n",
      "Train Epoch: 0 [68% 240/352]\tLoss: 1.901188\tData (t) 1.763\tBatch (t) 2.169\n",
      "Train Epoch: 0 [74% 260/352]\tLoss: 2.136467\tData (t) 1.975\tBatch (t) 2.050\n",
      "Train Epoch: 0 [80% 280/352]\tLoss: 1.842118\tData (t) 1.984\tBatch (t) 2.053\n",
      "Train Epoch: 0 [85% 300/352]\tLoss: 2.115879\tData (t) 1.965\tBatch (t) 2.015\n",
      "Train Epoch: 0 [91% 320/352]\tLoss: 2.066776\tData (t) 1.974\tBatch (t) 2.022\n",
      "Train Epoch: 0 [97% 340/352]\tLoss: 1.872259\tData (t) 2.027\tBatch (t) 2.310\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.9575   Acc: 53.97: 100% 40/40 [00:50<00:00,  1.26s/it]\n",
      "Val acc at epoch 0: 53.97\n",
      "Saving model to ./config4_1.pt\n",
      "Train Epoch: 1 [0% 0/352]\tLoss: 1.956558\tData (t) 10.727\tBatch (t) 11.194\n",
      "Train Epoch: 1 [6% 20/352]\tLoss: 2.178433\tData (t) 2.043\tBatch (t) 2.116\n",
      "Train Epoch: 1 [11% 40/352]\tLoss: 1.847307\tData (t) 2.014\tBatch (t) 2.082\n",
      "Train Epoch: 1 [17% 60/352]\tLoss: 1.907821\tData (t) 2.007\tBatch (t) 2.107\n",
      "Train Epoch: 1 [23% 80/352]\tLoss: 1.891371\tData (t) 2.023\tBatch (t) 2.093\n",
      "Train Epoch: 1 [28% 100/352]\tLoss: 1.887058\tData (t) 1.979\tBatch (t) 2.337\n",
      "Train Epoch: 1 [34% 120/352]\tLoss: 2.008329\tData (t) 2.035\tBatch (t) 2.067\n",
      "Train Epoch: 1 [40% 140/352]\tLoss: 1.864542\tData (t) 2.040\tBatch (t) 2.071\n",
      "Train Epoch: 1 [45% 160/352]\tLoss: 1.818202\tData (t) 2.043\tBatch (t) 2.074\n",
      "Train Epoch: 1 [51% 180/352]\tLoss: 1.858009\tData (t) 2.036\tBatch (t) 2.077\n",
      "Train Epoch: 1 [57% 200/352]\tLoss: 1.899758\tData (t) 2.020\tBatch (t) 2.052\n",
      "Train Epoch: 1 [62% 220/352]\tLoss: 1.651940\tData (t) 1.989\tBatch (t) 2.022\n",
      "Train Epoch: 1 [68% 240/352]\tLoss: 1.796330\tData (t) 1.992\tBatch (t) 2.026\n",
      "Train Epoch: 1 [74% 260/352]\tLoss: 1.735942\tData (t) 1.975\tBatch (t) 2.029\n",
      "Train Epoch: 1 [80% 280/352]\tLoss: 1.754004\tData (t) 2.022\tBatch (t) 2.281\n",
      "Train Epoch: 1 [85% 300/352]\tLoss: 1.626352\tData (t) 1.702\tBatch (t) 2.187\n",
      "Train Epoch: 1 [91% 320/352]\tLoss: 1.884002\tData (t) 1.781\tBatch (t) 2.117\n",
      "Train Epoch: 1 [97% 340/352]\tLoss: 1.685472\tData (t) 2.019\tBatch (t) 2.067\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.3504   Acc: 57.07: 100% 40/40 [00:57<00:00,  1.43s/it]\n",
      "Val acc at epoch 1: 57.07\n",
      "Saving model to ./config4_2.pt\n",
      "Train Epoch: 2 [0% 0/352]\tLoss: 1.444750\tData (t) 7.478\tBatch (t) 7.925\n",
      "Train Epoch: 2 [6% 20/352]\tLoss: 1.481389\tData (t) 1.289\tBatch (t) 1.986\n",
      "Train Epoch: 2 [11% 40/352]\tLoss: 1.772088\tData (t) 1.557\tBatch (t) 2.048\n",
      "Train Epoch: 2 [17% 60/352]\tLoss: 1.659999\tData (t) 2.054\tBatch (t) 2.085\n",
      "Train Epoch: 2 [23% 80/352]\tLoss: 1.681903\tData (t) 2.037\tBatch (t) 2.286\n",
      "Train Epoch: 2 [28% 100/352]\tLoss: 1.679308\tData (t) 1.734\tBatch (t) 1.791\n",
      "Train Epoch: 2 [34% 120/352]\tLoss: 1.922280\tData (t) 1.967\tBatch (t) 2.015\n",
      "Train Epoch: 2 [40% 140/352]\tLoss: 1.659079\tData (t) 2.018\tBatch (t) 2.049\n",
      "Train Epoch: 2 [45% 160/352]\tLoss: 1.697760\tData (t) 2.025\tBatch (t) 2.058\n",
      "Train Epoch: 2 [51% 180/352]\tLoss: 1.678767\tData (t) 2.026\tBatch (t) 2.058\n",
      "Train Epoch: 2 [57% 200/352]\tLoss: 1.446963\tData (t) 2.026\tBatch (t) 2.066\n",
      "Train Epoch: 2 [62% 220/352]\tLoss: 1.560400\tData (t) 1.969\tBatch (t) 2.013\n",
      "Train Epoch: 2 [68% 240/352]\tLoss: 1.698651\tData (t) 2.004\tBatch (t) 2.052\n",
      "Train Epoch: 2 [74% 260/352]\tLoss: 1.746687\tData (t) 1.969\tBatch (t) 2.029\n",
      "Train Epoch: 2 [80% 280/352]\tLoss: 1.438398\tData (t) 1.996\tBatch (t) 2.050\n",
      "Train Epoch: 2 [85% 300/352]\tLoss: 1.293065\tData (t) 2.005\tBatch (t) 2.053\n",
      "Train Epoch: 2 [91% 320/352]\tLoss: 1.542468\tData (t) 1.975\tBatch (t) 2.041\n",
      "Train Epoch: 2 [97% 340/352]\tLoss: 1.778425\tData (t) 2.018\tBatch (t) 2.232\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.3550   Acc: 59.94: 100% 40/40 [00:51<00:00,  1.30s/it]\n",
      "Val acc at epoch 2: 59.94\n",
      "Saving model to ./config4_3.pt\n",
      "Train Epoch: 3 [0% 0/352]\tLoss: 1.441822\tData (t) 11.329\tBatch (t) 11.633\n",
      "Train Epoch: 3 [6% 20/352]\tLoss: 1.489492\tData (t) 2.071\tBatch (t) 2.121\n",
      "Train Epoch: 3 [11% 40/352]\tLoss: 1.481040\tData (t) 1.992\tBatch (t) 2.024\n",
      "Train Epoch: 3 [17% 60/352]\tLoss: 1.406862\tData (t) 2.037\tBatch (t) 2.084\n",
      "Train Epoch: 3 [23% 80/352]\tLoss: 1.347749\tData (t) 1.655\tBatch (t) 2.227\n",
      "Train Epoch: 3 [28% 100/352]\tLoss: 1.500801\tData (t) 1.653\tBatch (t) 2.090\n",
      "Train Epoch: 3 [34% 120/352]\tLoss: 1.531621\tData (t) 1.842\tBatch (t) 2.084\n",
      "Train Epoch: 3 [40% 140/352]\tLoss: 1.461180\tData (t) 1.916\tBatch (t) 2.181\n",
      "Train Epoch: 3 [45% 160/352]\tLoss: 1.281556\tData (t) 2.044\tBatch (t) 2.354\n",
      "Train Epoch: 3 [51% 180/352]\tLoss: 1.694699\tData (t) 2.027\tBatch (t) 2.079\n",
      "Train Epoch: 3 [57% 200/352]\tLoss: 1.542373\tData (t) 2.030\tBatch (t) 2.062\n",
      "Train Epoch: 3 [62% 220/352]\tLoss: 1.625910\tData (t) 2.018\tBatch (t) 2.051\n",
      "Train Epoch: 3 [68% 240/352]\tLoss: 1.479071\tData (t) 2.024\tBatch (t) 2.055\n",
      "Train Epoch: 3 [74% 260/352]\tLoss: 1.236661\tData (t) 2.020\tBatch (t) 2.423\n",
      "Train Epoch: 3 [80% 280/352]\tLoss: 1.550960\tData (t) 1.778\tBatch (t) 2.102\n",
      "Train Epoch: 3 [85% 300/352]\tLoss: 1.617999\tData (t) 2.041\tBatch (t) 2.076\n",
      "Train Epoch: 3 [91% 320/352]\tLoss: 1.399518\tData (t) 1.450\tBatch (t) 2.185\n",
      "Train Epoch: 3 [97% 340/352]\tLoss: 1.434320\tData (t) 2.034\tBatch (t) 2.065\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.1451   Acc: 60.94: 100% 40/40 [00:53<00:00,  1.34s/it]\n",
      "Val acc at epoch 3: 60.94\n",
      "Saving model to ./config4_4.pt\n",
      "Train Epoch: 4 [0% 0/352]\tLoss: 1.127196\tData (t) 9.255\tBatch (t) 9.540\n",
      "Train Epoch: 4 [6% 20/352]\tLoss: 1.339646\tData (t) 2.036\tBatch (t) 2.068\n",
      "Train Epoch: 4 [11% 40/352]\tLoss: 1.363666\tData (t) 2.002\tBatch (t) 2.033\n",
      "Train Epoch: 4 [17% 60/352]\tLoss: 1.348864\tData (t) 2.030\tBatch (t) 2.062\n",
      "Train Epoch: 4 [23% 80/352]\tLoss: 1.283372\tData (t) 2.016\tBatch (t) 2.068\n",
      "Train Epoch: 4 [28% 100/352]\tLoss: 1.349254\tData (t) 2.015\tBatch (t) 2.063\n",
      "Train Epoch: 4 [34% 120/352]\tLoss: 1.171003\tData (t) 2.017\tBatch (t) 2.067\n",
      "Train Epoch: 4 [40% 140/352]\tLoss: 1.341178\tData (t) 1.998\tBatch (t) 2.046\n",
      "Train Epoch: 4 [45% 160/352]\tLoss: 1.428798\tData (t) 2.003\tBatch (t) 2.052\n",
      "Train Epoch: 4 [51% 180/352]\tLoss: 1.264622\tData (t) 1.981\tBatch (t) 2.028\n",
      "Train Epoch: 4 [57% 200/352]\tLoss: 1.226815\tData (t) 1.965\tBatch (t) 2.014\n",
      "Train Epoch: 4 [62% 220/352]\tLoss: 1.585469\tData (t) 1.767\tBatch (t) 1.950\n",
      "Train Epoch: 4 [68% 240/352]\tLoss: 1.328398\tData (t) 1.951\tBatch (t) 2.101\n",
      "Train Epoch: 4 [74% 260/352]\tLoss: 1.315127\tData (t) 1.977\tBatch (t) 2.020\n",
      "Train Epoch: 4 [80% 280/352]\tLoss: 1.152453\tData (t) 1.935\tBatch (t) 2.105\n",
      "Train Epoch: 4 [85% 300/352]\tLoss: 1.219202\tData (t) 1.701\tBatch (t) 2.285\n",
      "Train Epoch: 4 [91% 320/352]\tLoss: 1.295661\tData (t) 2.033\tBatch (t) 2.109\n",
      "Train Epoch: 4 [97% 340/352]\tLoss: 1.408458\tData (t) 1.850\tBatch (t) 2.046\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.7125   Acc: 63.50: 100% 40/40 [00:50<00:00,  1.27s/it]\n",
      "Val acc at epoch 4: 63.50\n",
      "Saving model to ./config4_5.pt\n",
      "Train Epoch: 5 [0% 0/352]\tLoss: 1.287405\tData (t) 8.793\tBatch (t) 9.279\n",
      "Train Epoch: 5 [6% 20/352]\tLoss: 0.995261\tData (t) 2.078\tBatch (t) 2.155\n",
      "Train Epoch: 5 [11% 40/352]\tLoss: 1.334487\tData (t) 2.013\tBatch (t) 2.064\n",
      "Train Epoch: 5 [17% 60/352]\tLoss: 1.190423\tData (t) 2.047\tBatch (t) 2.079\n",
      "Train Epoch: 5 [23% 80/352]\tLoss: 1.226589\tData (t) 2.013\tBatch (t) 2.065\n",
      "Train Epoch: 5 [28% 100/352]\tLoss: 1.194247\tData (t) 1.506\tBatch (t) 2.065\n",
      "Train Epoch: 5 [34% 120/352]\tLoss: 1.223211\tData (t) 2.040\tBatch (t) 2.355\n",
      "Train Epoch: 5 [40% 140/352]\tLoss: 1.161648\tData (t) 1.416\tBatch (t) 2.327\n",
      "Train Epoch: 5 [45% 160/352]\tLoss: 1.320092\tData (t) 1.943\tBatch (t) 1.990\n",
      "Train Epoch: 5 [51% 180/352]\tLoss: 1.401924\tData (t) 1.924\tBatch (t) 1.993\n",
      "Train Epoch: 5 [57% 200/352]\tLoss: 1.151597\tData (t) 1.921\tBatch (t) 2.034\n",
      "Train Epoch: 5 [62% 220/352]\tLoss: 1.009274\tData (t) 1.718\tBatch (t) 1.891\n",
      "Train Epoch: 5 [68% 240/352]\tLoss: 1.144514\tData (t) 1.984\tBatch (t) 2.032\n",
      "Train Epoch: 5 [74% 260/352]\tLoss: 1.070089\tData (t) 1.747\tBatch (t) 1.891\n",
      "Train Epoch: 5 [80% 280/352]\tLoss: 1.102438\tData (t) 2.001\tBatch (t) 2.054\n",
      "Train Epoch: 5 [85% 300/352]\tLoss: 1.127967\tData (t) 2.028\tBatch (t) 2.076\n",
      "Train Epoch: 5 [91% 320/352]\tLoss: 1.105364\tData (t) 1.734\tBatch (t) 2.040\n",
      "Train Epoch: 5 [97% 340/352]\tLoss: 1.204669\tData (t) 1.971\tBatch (t) 2.107\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.1996   Acc: 64.81: 100% 40/40 [00:48<00:00,  1.22s/it]\n",
      "Val acc at epoch 5: 64.81\n",
      "Saving model to ./config4_6.pt\n",
      "Train Epoch: 6 [0% 0/352]\tLoss: 0.871250\tData (t) 9.583\tBatch (t) 10.209\n",
      "Train Epoch: 6 [6% 20/352]\tLoss: 1.195513\tData (t) 1.884\tBatch (t) 2.202\n",
      "Train Epoch: 6 [11% 40/352]\tLoss: 1.197906\tData (t) 1.570\tBatch (t) 1.674\n",
      "Train Epoch: 6 [17% 60/352]\tLoss: 1.014491\tData (t) 2.037\tBatch (t) 2.092\n",
      "Train Epoch: 6 [23% 80/352]\tLoss: 0.958766\tData (t) 2.010\tBatch (t) 2.101\n",
      "Train Epoch: 6 [28% 100/352]\tLoss: 1.082414\tData (t) 2.026\tBatch (t) 2.113\n",
      "Train Epoch: 6 [34% 120/352]\tLoss: 0.966647\tData (t) 1.540\tBatch (t) 1.925\n",
      "Train Epoch: 6 [40% 140/352]\tLoss: 0.992274\tData (t) 1.715\tBatch (t) 1.818\n",
      "Train Epoch: 6 [45% 160/352]\tLoss: 1.128404\tData (t) 2.025\tBatch (t) 2.092\n",
      "Train Epoch: 6 [51% 180/352]\tLoss: 1.124886\tData (t) 2.039\tBatch (t) 2.105\n",
      "Train Epoch: 6 [57% 200/352]\tLoss: 1.059141\tData (t) 2.033\tBatch (t) 2.075\n",
      "Train Epoch: 6 [62% 220/352]\tLoss: 1.014565\tData (t) 2.043\tBatch (t) 2.074\n",
      "Train Epoch: 6 [68% 240/352]\tLoss: 0.920213\tData (t) 2.043\tBatch (t) 2.075\n",
      "Train Epoch: 6 [74% 260/352]\tLoss: 1.144994\tData (t) 1.424\tBatch (t) 1.693\n",
      "Train Epoch: 6 [80% 280/352]\tLoss: 1.293874\tData (t) 1.690\tBatch (t) 1.980\n",
      "Train Epoch: 6 [85% 300/352]\tLoss: 0.915213\tData (t) 1.677\tBatch (t) 1.740\n",
      "Train Epoch: 6 [91% 320/352]\tLoss: 1.080406\tData (t) 1.436\tBatch (t) 2.244\n",
      "Train Epoch: 6 [97% 340/352]\tLoss: 1.027332\tData (t) 2.026\tBatch (t) 2.057\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.7815   Acc: 65.85: 100% 40/40 [00:55<00:00,  1.39s/it]\n",
      "Val acc at epoch 6: 65.85\n",
      "Saving model to ./config4_7.pt\n",
      "Train Epoch: 7 [0% 0/352]\tLoss: 0.807386\tData (t) 14.085\tBatch (t) 15.128\n",
      "Train Epoch: 7 [6% 20/352]\tLoss: 1.099274\tData (t) 1.791\tBatch (t) 1.905\n",
      "Train Epoch: 7 [11% 40/352]\tLoss: 0.961717\tData (t) 1.953\tBatch (t) 2.075\n",
      "Train Epoch: 7 [17% 60/352]\tLoss: 0.977368\tData (t) 1.792\tBatch (t) 2.205\n",
      "Train Epoch: 7 [23% 80/352]\tLoss: 0.888976\tData (t) 2.032\tBatch (t) 2.134\n",
      "Train Epoch: 7 [28% 100/352]\tLoss: 1.155100\tData (t) 2.031\tBatch (t) 2.086\n",
      "Train Epoch: 7 [34% 120/352]\tLoss: 0.938048\tData (t) 2.035\tBatch (t) 2.067\n",
      "Train Epoch: 7 [40% 140/352]\tLoss: 0.768538\tData (t) 1.595\tBatch (t) 1.899\n",
      "Train Epoch: 7 [45% 160/352]\tLoss: 1.150117\tData (t) 1.889\tBatch (t) 2.241\n",
      "Train Epoch: 7 [51% 180/352]\tLoss: 1.050574\tData (t) 1.645\tBatch (t) 2.152\n",
      "Train Epoch: 7 [57% 200/352]\tLoss: 0.966412\tData (t) 1.568\tBatch (t) 2.281\n",
      "Train Epoch: 7 [62% 220/352]\tLoss: 1.029784\tData (t) 1.734\tBatch (t) 2.030\n",
      "Train Epoch: 7 [68% 240/352]\tLoss: 0.722690\tData (t) 1.677\tBatch (t) 1.853\n",
      "Train Epoch: 7 [74% 260/352]\tLoss: 0.792969\tData (t) 2.020\tBatch (t) 2.075\n",
      "Train Epoch: 7 [80% 280/352]\tLoss: 0.871943\tData (t) 1.575\tBatch (t) 2.022\n",
      "Train Epoch: 7 [85% 300/352]\tLoss: 0.851016\tData (t) 1.980\tBatch (t) 2.030\n",
      "Train Epoch: 7 [91% 320/352]\tLoss: 0.986487\tData (t) 1.965\tBatch (t) 2.016\n",
      "Train Epoch: 7 [97% 340/352]\tLoss: 1.025280\tData (t) 2.023\tBatch (t) 2.072\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.0353   Acc: 67.00: 100% 40/40 [00:55<00:00,  1.38s/it]\n",
      "Val acc at epoch 7: 67.00\n",
      "Saving model to ./config4_8.pt\n",
      "Train Epoch: 8 [0% 0/352]\tLoss: 0.908187\tData (t) 10.147\tBatch (t) 11.712\n",
      "Train Epoch: 8 [6% 20/352]\tLoss: 0.897846\tData (t) 1.725\tBatch (t) 2.164\n",
      "Train Epoch: 8 [11% 40/352]\tLoss: 0.931017\tData (t) 1.819\tBatch (t) 2.193\n",
      "Train Epoch: 8 [17% 60/352]\tLoss: 0.921625\tData (t) 1.899\tBatch (t) 2.206\n",
      "Train Epoch: 8 [23% 80/352]\tLoss: 0.744111\tData (t) 2.038\tBatch (t) 2.360\n",
      "Train Epoch: 8 [28% 100/352]\tLoss: 0.589181\tData (t) 1.834\tBatch (t) 2.024\n",
      "Train Epoch: 8 [34% 120/352]\tLoss: 1.035614\tData (t) 1.696\tBatch (t) 2.078\n",
      "Train Epoch: 8 [40% 140/352]\tLoss: 0.997585\tData (t) 1.673\tBatch (t) 2.280\n",
      "Train Epoch: 8 [45% 160/352]\tLoss: 0.866436\tData (t) 1.656\tBatch (t) 2.240\n",
      "Train Epoch: 8 [51% 180/352]\tLoss: 0.879002\tData (t) 1.658\tBatch (t) 1.707\n",
      "Train Epoch: 8 [57% 200/352]\tLoss: 0.952779\tData (t) 1.501\tBatch (t) 2.040\n",
      "Train Epoch: 8 [62% 220/352]\tLoss: 0.883705\tData (t) 1.740\tBatch (t) 2.218\n",
      "Train Epoch: 8 [68% 240/352]\tLoss: 0.827332\tData (t) 1.477\tBatch (t) 1.775\n",
      "Train Epoch: 8 [74% 260/352]\tLoss: 0.905580\tData (t) 2.024\tBatch (t) 2.055\n",
      "Train Epoch: 8 [80% 280/352]\tLoss: 0.888685\tData (t) 1.894\tBatch (t) 2.217\n",
      "Train Epoch: 8 [85% 300/352]\tLoss: 0.956931\tData (t) 1.779\tBatch (t) 2.163\n",
      "Train Epoch: 8 [91% 320/352]\tLoss: 0.984040\tData (t) 1.194\tBatch (t) 1.901\n",
      "Train Epoch: 8 [97% 340/352]\tLoss: 0.974589\tData (t) 2.037\tBatch (t) 2.068\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.9735   Acc: 67.86: 100% 40/40 [00:51<00:00,  1.29s/it]\n",
      "Val acc at epoch 8: 67.86\n",
      "Saving model to ./config4_9.pt\n",
      "Train Epoch: 9 [0% 0/352]\tLoss: 1.043026\tData (t) 13.462\tBatch (t) 14.231\n",
      "Train Epoch: 9 [6% 20/352]\tLoss: 1.120823\tData (t) 2.010\tBatch (t) 2.096\n",
      "Train Epoch: 9 [11% 40/352]\tLoss: 0.731964\tData (t) 1.948\tBatch (t) 1.995\n",
      "Train Epoch: 9 [17% 60/352]\tLoss: 0.755099\tData (t) 2.018\tBatch (t) 2.069\n",
      "Train Epoch: 9 [23% 80/352]\tLoss: 1.034172\tData (t) 2.017\tBatch (t) 2.063\n",
      "Train Epoch: 9 [28% 100/352]\tLoss: 0.860669\tData (t) 2.016\tBatch (t) 2.063\n",
      "Train Epoch: 9 [34% 120/352]\tLoss: 0.900929\tData (t) 1.988\tBatch (t) 2.040\n",
      "Train Epoch: 9 [40% 140/352]\tLoss: 0.752061\tData (t) 1.833\tBatch (t) 2.194\n",
      "Train Epoch: 9 [45% 160/352]\tLoss: 1.017275\tData (t) 2.043\tBatch (t) 2.119\n",
      "Train Epoch: 9 [51% 180/352]\tLoss: 0.831608\tData (t) 2.038\tBatch (t) 2.144\n",
      "Train Epoch: 9 [57% 200/352]\tLoss: 0.802452\tData (t) 2.042\tBatch (t) 2.092\n",
      "Train Epoch: 9 [62% 220/352]\tLoss: 0.819054\tData (t) 1.726\tBatch (t) 1.931\n",
      "Train Epoch: 9 [68% 240/352]\tLoss: 0.706940\tData (t) 2.039\tBatch (t) 2.070\n",
      "Train Epoch: 9 [74% 260/352]\tLoss: 0.825359\tData (t) 2.022\tBatch (t) 2.570\n",
      "Train Epoch: 9 [80% 280/352]\tLoss: 0.866080\tData (t) 2.038\tBatch (t) 2.070\n",
      "Train Epoch: 9 [85% 300/352]\tLoss: 0.950668\tData (t) 2.035\tBatch (t) 2.066\n",
      "Train Epoch: 9 [91% 320/352]\tLoss: 0.943301\tData (t) 2.032\tBatch (t) 2.063\n",
      "Train Epoch: 9 [97% 340/352]\tLoss: 0.966110\tData (t) 2.036\tBatch (t) 2.068\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 0.8298   Acc: 67.90: 100% 40/40 [00:49<00:00,  1.24s/it]\n",
      "Val acc at epoch 9: 67.90\n",
      "Saving model to ./config4_10.pt\n",
      "✅ Configuration 4 completed and backed up to Drive!\n"
     ]
    }
   ],
   "source": [
    "# Configuration 4: lr=2e-5, wd=1e-3, epochs=10, batch_size=256, timm_aug=True\n",
    "!python $CODE_DIR/finetune.py --lr 2e-5 --wd 1e-3 --epochs 10 --batch-size 256 --timm-aug --data-location $DATA_DIR --name \"config4\"\n",
    "\n",
    "# Backup model to Google Drive\n",
    "!cp config4_*.pt \"/content/drive/MyDrive/Colab Notebooks/\"\n",
    "print(\"✅ Configuration 4 completed and backed up to Drive!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8145479,
     "status": "ok",
     "timestamp": 1755960565429,
     "user": {
      "displayName": "Yang Zhou",
      "userId": "09717432835810465973"
     },
     "user_tz": 240
    },
    "id": "MOn2lXyxuByF",
    "outputId": "358884ec-c69d-4547-f4c6-d3428412f663"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Building zero-shot classifier.\n",
      "100% 200/200 [00:12<00:00, 16.65it/s]\n",
      "Saving model to ./config5_0.pt\n",
      "Train Epoch: 0 [0% 0/352]\tLoss: 1.430876\tData (t) 13.988\tBatch (t) 19.614\n",
      "Train Epoch: 0 [6% 20/352]\tLoss: 1.671773\tData (t) 2.032\tBatch (t) 2.335\n",
      "Train Epoch: 0 [11% 40/352]\tLoss: 1.435908\tData (t) 2.023\tBatch (t) 2.070\n",
      "Train Epoch: 0 [17% 60/352]\tLoss: 1.195043\tData (t) 2.033\tBatch (t) 2.081\n",
      "Train Epoch: 0 [23% 80/352]\tLoss: 1.295531\tData (t) 2.033\tBatch (t) 2.066\n",
      "Train Epoch: 0 [28% 100/352]\tLoss: 1.165548\tData (t) 1.821\tBatch (t) 1.852\n",
      "Train Epoch: 0 [34% 120/352]\tLoss: 1.359950\tData (t) 1.803\tBatch (t) 1.834\n",
      "Train Epoch: 0 [40% 140/352]\tLoss: 1.352595\tData (t) 1.812\tBatch (t) 1.844\n",
      "Train Epoch: 0 [45% 160/352]\tLoss: 1.147962\tData (t) 1.799\tBatch (t) 1.831\n",
      "Train Epoch: 0 [51% 180/352]\tLoss: 1.303125\tData (t) 2.039\tBatch (t) 2.071\n",
      "Train Epoch: 0 [57% 200/352]\tLoss: 0.973293\tData (t) 1.796\tBatch (t) 1.830\n",
      "Train Epoch: 0 [62% 220/352]\tLoss: 1.075627\tData (t) 2.036\tBatch (t) 2.067\n",
      "Train Epoch: 0 [68% 240/352]\tLoss: 1.115972\tData (t) 1.789\tBatch (t) 1.821\n",
      "Train Epoch: 0 [74% 260/352]\tLoss: 1.143139\tData (t) 2.030\tBatch (t) 2.067\n",
      "Train Epoch: 0 [80% 280/352]\tLoss: 0.995153\tData (t) 2.033\tBatch (t) 2.064\n",
      "Train Epoch: 0 [85% 300/352]\tLoss: 1.041163\tData (t) 2.038\tBatch (t) 2.311\n",
      "Train Epoch: 0 [91% 320/352]\tLoss: 1.082978\tData (t) 2.029\tBatch (t) 2.061\n",
      "Train Epoch: 0 [97% 340/352]\tLoss: 0.975382\tData (t) 2.039\tBatch (t) 2.193\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.7508   Acc: 73.35: 100% 40/40 [00:39<00:00,  1.02it/s]\n",
      "Val acc at epoch 0: 73.35\n",
      "Saving model to ./config5_1.pt\n",
      "Train Epoch: 1 [0% 0/352]\tLoss: 1.012269\tData (t) 9.627\tBatch (t) 11.156\n",
      "Train Epoch: 1 [6% 20/352]\tLoss: 1.199017\tData (t) 2.056\tBatch (t) 2.105\n",
      "Train Epoch: 1 [11% 40/352]\tLoss: 0.701922\tData (t) 1.987\tBatch (t) 2.041\n",
      "Train Epoch: 1 [17% 60/352]\tLoss: 0.923861\tData (t) 2.033\tBatch (t) 2.065\n",
      "Train Epoch: 1 [23% 80/352]\tLoss: 0.869257\tData (t) 2.016\tBatch (t) 2.048\n",
      "Train Epoch: 1 [28% 100/352]\tLoss: 0.887115\tData (t) 2.015\tBatch (t) 2.046\n",
      "Train Epoch: 1 [34% 120/352]\tLoss: 0.983095\tData (t) 2.013\tBatch (t) 2.045\n",
      "Train Epoch: 1 [40% 140/352]\tLoss: 0.853483\tData (t) 2.007\tBatch (t) 2.040\n",
      "Train Epoch: 1 [45% 160/352]\tLoss: 0.811381\tData (t) 2.040\tBatch (t) 2.072\n",
      "Train Epoch: 1 [51% 180/352]\tLoss: 0.907304\tData (t) 2.034\tBatch (t) 2.066\n",
      "Train Epoch: 1 [57% 200/352]\tLoss: 0.899913\tData (t) 2.036\tBatch (t) 2.275\n",
      "Train Epoch: 1 [62% 220/352]\tLoss: 0.965076\tData (t) 2.033\tBatch (t) 2.237\n",
      "Train Epoch: 1 [68% 240/352]\tLoss: 0.770086\tData (t) 2.030\tBatch (t) 2.237\n",
      "Train Epoch: 1 [74% 260/352]\tLoss: 0.831856\tData (t) 1.866\tBatch (t) 2.187\n",
      "Train Epoch: 1 [80% 280/352]\tLoss: 0.768492\tData (t) 1.831\tBatch (t) 2.106\n",
      "Train Epoch: 1 [85% 300/352]\tLoss: 0.761004\tData (t) 1.801\tBatch (t) 2.057\n",
      "Train Epoch: 1 [91% 320/352]\tLoss: 0.801376\tData (t) 1.842\tBatch (t) 2.062\n",
      "Train Epoch: 1 [97% 340/352]\tLoss: 0.717733\tData (t) 2.040\tBatch (t) 2.073\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.3466   Acc: 77.10: 100% 40/40 [00:35<00:00,  1.13it/s]\n",
      "Val acc at epoch 1: 77.10\n",
      "Saving model to ./config5_2.pt\n",
      "Train Epoch: 2 [0% 0/352]\tLoss: 0.777507\tData (t) 6.565\tBatch (t) 6.841\n",
      "Train Epoch: 2 [6% 20/352]\tLoss: 0.754846\tData (t) 2.062\tBatch (t) 2.105\n",
      "Train Epoch: 2 [11% 40/352]\tLoss: 0.666979\tData (t) 2.011\tBatch (t) 2.051\n",
      "Train Epoch: 2 [17% 60/352]\tLoss: 0.678192\tData (t) 2.047\tBatch (t) 2.079\n",
      "Train Epoch: 2 [23% 80/352]\tLoss: 0.824914\tData (t) 2.033\tBatch (t) 2.066\n",
      "Train Epoch: 2 [28% 100/352]\tLoss: 0.641474\tData (t) 2.038\tBatch (t) 2.069\n",
      "Train Epoch: 2 [34% 120/352]\tLoss: 0.729982\tData (t) 1.867\tBatch (t) 2.109\n",
      "Train Epoch: 2 [40% 140/352]\tLoss: 0.675222\tData (t) 2.036\tBatch (t) 2.067\n",
      "Train Epoch: 2 [45% 160/352]\tLoss: 0.681803\tData (t) 2.037\tBatch (t) 2.069\n",
      "Train Epoch: 2 [51% 180/352]\tLoss: 0.711249\tData (t) 2.038\tBatch (t) 2.080\n",
      "Train Epoch: 2 [57% 200/352]\tLoss: 0.690822\tData (t) 2.033\tBatch (t) 2.079\n",
      "Train Epoch: 2 [62% 220/352]\tLoss: 0.641407\tData (t) 2.024\tBatch (t) 2.071\n",
      "Train Epoch: 2 [68% 240/352]\tLoss: 0.722968\tData (t) 2.025\tBatch (t) 2.067\n",
      "Train Epoch: 2 [74% 260/352]\tLoss: 0.585187\tData (t) 2.005\tBatch (t) 2.036\n",
      "Train Epoch: 2 [80% 280/352]\tLoss: 0.632622\tData (t) 1.831\tBatch (t) 1.865\n",
      "Train Epoch: 2 [85% 300/352]\tLoss: 0.642740\tData (t) 2.021\tBatch (t) 2.056\n",
      "Train Epoch: 2 [91% 320/352]\tLoss: 0.836868\tData (t) 2.031\tBatch (t) 2.063\n",
      "Train Epoch: 2 [97% 340/352]\tLoss: 0.682153\tData (t) 2.029\tBatch (t) 2.060\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.6620   Acc: 78.31: 100% 40/40 [00:38<00:00,  1.04it/s]\n",
      "Val acc at epoch 2: 78.31\n",
      "Saving model to ./config5_3.pt\n",
      "Train Epoch: 3 [0% 0/352]\tLoss: 0.494101\tData (t) 8.803\tBatch (t) 9.077\n",
      "Train Epoch: 3 [6% 20/352]\tLoss: 0.635498\tData (t) 2.072\tBatch (t) 2.104\n",
      "Train Epoch: 3 [11% 40/352]\tLoss: 0.449384\tData (t) 2.012\tBatch (t) 2.044\n",
      "Train Epoch: 3 [17% 60/352]\tLoss: 0.605136\tData (t) 2.050\tBatch (t) 2.083\n",
      "Train Epoch: 3 [23% 80/352]\tLoss: 0.574960\tData (t) 2.032\tBatch (t) 2.063\n",
      "Train Epoch: 3 [28% 100/352]\tLoss: 0.487305\tData (t) 2.026\tBatch (t) 2.072\n",
      "Train Epoch: 3 [34% 120/352]\tLoss: 0.541073\tData (t) 1.874\tBatch (t) 2.071\n",
      "Train Epoch: 3 [40% 140/352]\tLoss: 0.530483\tData (t) 2.042\tBatch (t) 2.074\n",
      "Train Epoch: 3 [45% 160/352]\tLoss: 0.562935\tData (t) 2.032\tBatch (t) 2.063\n",
      "Train Epoch: 3 [51% 180/352]\tLoss: 0.609307\tData (t) 2.030\tBatch (t) 2.065\n",
      "Train Epoch: 3 [57% 200/352]\tLoss: 0.535473\tData (t) 2.030\tBatch (t) 2.079\n",
      "Train Epoch: 3 [62% 220/352]\tLoss: 0.577255\tData (t) 2.033\tBatch (t) 2.075\n",
      "Train Epoch: 3 [68% 240/352]\tLoss: 0.529458\tData (t) 2.015\tBatch (t) 2.060\n",
      "Train Epoch: 3 [74% 260/352]\tLoss: 0.476237\tData (t) 2.020\tBatch (t) 2.272\n",
      "Train Epoch: 3 [80% 280/352]\tLoss: 0.580042\tData (t) 1.855\tBatch (t) 1.949\n",
      "Train Epoch: 3 [85% 300/352]\tLoss: 0.559105\tData (t) 2.017\tBatch (t) 2.055\n",
      "Train Epoch: 3 [91% 320/352]\tLoss: 0.707017\tData (t) 2.033\tBatch (t) 2.064\n",
      "Train Epoch: 3 [97% 340/352]\tLoss: 0.670715\tData (t) 2.035\tBatch (t) 2.067\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.4092   Acc: 79.00: 100% 40/40 [00:35<00:00,  1.12it/s]\n",
      "Val acc at epoch 3: 79.00\n",
      "Saving model to ./config5_4.pt\n",
      "Train Epoch: 4 [0% 0/352]\tLoss: 0.389467\tData (t) 6.472\tBatch (t) 6.741\n",
      "Train Epoch: 4 [6% 20/352]\tLoss: 0.440723\tData (t) 2.081\tBatch (t) 2.117\n",
      "Train Epoch: 4 [11% 40/352]\tLoss: 0.426568\tData (t) 2.012\tBatch (t) 2.045\n",
      "Train Epoch: 4 [17% 60/352]\tLoss: 0.426283\tData (t) 2.050\tBatch (t) 2.081\n",
      "Train Epoch: 4 [23% 80/352]\tLoss: 0.486069\tData (t) 2.031\tBatch (t) 2.062\n",
      "Train Epoch: 4 [28% 100/352]\tLoss: 0.477017\tData (t) 2.033\tBatch (t) 2.065\n",
      "Train Epoch: 4 [34% 120/352]\tLoss: 0.504004\tData (t) 2.034\tBatch (t) 2.065\n",
      "Train Epoch: 4 [40% 140/352]\tLoss: 0.517332\tData (t) 2.035\tBatch (t) 2.071\n",
      "Train Epoch: 4 [45% 160/352]\tLoss: 0.482983\tData (t) 1.874\tBatch (t) 2.072\n",
      "Train Epoch: 4 [51% 180/352]\tLoss: 0.387650\tData (t) 1.873\tBatch (t) 1.904\n",
      "Train Epoch: 4 [57% 200/352]\tLoss: 0.544304\tData (t) 2.034\tBatch (t) 2.065\n",
      "Train Epoch: 4 [62% 220/352]\tLoss: 0.443073\tData (t) 2.024\tBatch (t) 2.055\n",
      "Train Epoch: 4 [68% 240/352]\tLoss: 0.351229\tData (t) 2.033\tBatch (t) 2.065\n",
      "Train Epoch: 4 [74% 260/352]\tLoss: 0.591774\tData (t) 2.036\tBatch (t) 2.080\n",
      "Train Epoch: 4 [80% 280/352]\tLoss: 0.350303\tData (t) 2.033\tBatch (t) 2.075\n",
      "Train Epoch: 4 [85% 300/352]\tLoss: 0.454949\tData (t) 2.011\tBatch (t) 2.049\n",
      "Train Epoch: 4 [91% 320/352]\tLoss: 0.408292\tData (t) 2.027\tBatch (t) 2.059\n",
      "Train Epoch: 4 [97% 340/352]\tLoss: 0.395154\tData (t) 2.021\tBatch (t) 2.052\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.3614   Acc: 79.03: 100% 40/40 [00:36<00:00,  1.10it/s]\n",
      "Val acc at epoch 4: 79.03\n",
      "Saving model to ./config5_5.pt\n",
      "Train Epoch: 5 [0% 0/352]\tLoss: 0.253681\tData (t) 6.137\tBatch (t) 6.603\n",
      "Train Epoch: 5 [6% 20/352]\tLoss: 0.301813\tData (t) 2.061\tBatch (t) 2.108\n",
      "Train Epoch: 5 [11% 40/352]\tLoss: 0.298415\tData (t) 1.994\tBatch (t) 2.037\n",
      "Train Epoch: 5 [17% 60/352]\tLoss: 0.329267\tData (t) 2.051\tBatch (t) 2.099\n",
      "Train Epoch: 5 [23% 80/352]\tLoss: 0.316593\tData (t) 2.028\tBatch (t) 2.060\n",
      "Train Epoch: 5 [28% 100/352]\tLoss: 0.303516\tData (t) 2.037\tBatch (t) 2.069\n",
      "Train Epoch: 5 [34% 120/352]\tLoss: 0.306512\tData (t) 2.044\tBatch (t) 2.075\n",
      "Train Epoch: 5 [40% 140/352]\tLoss: 0.308422\tData (t) 2.034\tBatch (t) 2.065\n",
      "Train Epoch: 5 [45% 160/352]\tLoss: 0.331257\tData (t) 2.031\tBatch (t) 2.063\n",
      "Train Epoch: 5 [51% 180/352]\tLoss: 0.451902\tData (t) 2.034\tBatch (t) 2.065\n",
      "Train Epoch: 5 [57% 200/352]\tLoss: 0.296165\tData (t) 2.033\tBatch (t) 2.066\n",
      "Train Epoch: 5 [62% 220/352]\tLoss: 0.526216\tData (t) 2.031\tBatch (t) 2.063\n",
      "Train Epoch: 5 [68% 240/352]\tLoss: 0.301761\tData (t) 2.031\tBatch (t) 2.064\n",
      "Train Epoch: 5 [74% 260/352]\tLoss: 0.324596\tData (t) 2.038\tBatch (t) 2.070\n",
      "Train Epoch: 5 [80% 280/352]\tLoss: 0.380589\tData (t) 2.017\tBatch (t) 2.048\n",
      "Train Epoch: 5 [85% 300/352]\tLoss: 0.286684\tData (t) 1.786\tBatch (t) 1.837\n",
      "Train Epoch: 5 [91% 320/352]\tLoss: 0.298365\tData (t) 1.936\tBatch (t) 2.269\n",
      "Train Epoch: 5 [97% 340/352]\tLoss: 0.300816\tData (t) 2.004\tBatch (t) 2.188\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.3570   Acc: 79.34: 100% 40/40 [00:40<00:00,  1.02s/it]\n",
      "Val acc at epoch 5: 79.34\n",
      "Saving model to ./config5_6.pt\n",
      "Train Epoch: 6 [0% 0/352]\tLoss: 0.267718\tData (t) 4.828\tBatch (t) 5.309\n",
      "Train Epoch: 6 [6% 20/352]\tLoss: 0.224023\tData (t) 2.062\tBatch (t) 2.106\n",
      "Train Epoch: 6 [11% 40/352]\tLoss: 0.367256\tData (t) 2.023\tBatch (t) 2.055\n",
      "Train Epoch: 6 [17% 60/352]\tLoss: 0.280695\tData (t) 2.041\tBatch (t) 2.073\n",
      "Train Epoch: 6 [23% 80/352]\tLoss: 0.235637\tData (t) 2.042\tBatch (t) 2.073\n",
      "Train Epoch: 6 [28% 100/352]\tLoss: 0.262912\tData (t) 2.036\tBatch (t) 2.067\n",
      "Train Epoch: 6 [34% 120/352]\tLoss: 0.283616\tData (t) 2.035\tBatch (t) 2.066\n",
      "Train Epoch: 6 [40% 140/352]\tLoss: 0.231787\tData (t) 2.035\tBatch (t) 2.066\n",
      "Train Epoch: 6 [45% 160/352]\tLoss: 0.232005\tData (t) 2.034\tBatch (t) 2.083\n",
      "Train Epoch: 6 [51% 180/352]\tLoss: 0.243381\tData (t) 2.035\tBatch (t) 2.094\n",
      "Train Epoch: 6 [57% 200/352]\tLoss: 0.199366\tData (t) 2.036\tBatch (t) 2.076\n",
      "Train Epoch: 6 [62% 220/352]\tLoss: 0.352027\tData (t) 2.030\tBatch (t) 2.061\n",
      "Train Epoch: 6 [68% 240/352]\tLoss: 0.287203\tData (t) 2.036\tBatch (t) 2.333\n",
      "Train Epoch: 6 [74% 260/352]\tLoss: 0.277123\tData (t) 2.035\tBatch (t) 2.066\n",
      "Train Epoch: 6 [80% 280/352]\tLoss: 0.206395\tData (t) 2.039\tBatch (t) 2.090\n",
      "Train Epoch: 6 [85% 300/352]\tLoss: 0.182937\tData (t) 1.875\tBatch (t) 2.202\n",
      "Train Epoch: 6 [91% 320/352]\tLoss: 0.227764\tData (t) 1.876\tBatch (t) 2.191\n",
      "Train Epoch: 6 [97% 340/352]\tLoss: 0.300737\tData (t) 1.879\tBatch (t) 2.149\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.6051   Acc: 79.32: 100% 40/40 [00:39<00:00,  1.00it/s]\n",
      "Val acc at epoch 6: 79.32\n",
      "Saving model to ./config5_7.pt\n",
      "Train Epoch: 7 [0% 0/352]\tLoss: 0.200202\tData (t) 11.272\tBatch (t) 11.724\n",
      "Train Epoch: 7 [6% 20/352]\tLoss: 0.312737\tData (t) 1.971\tBatch (t) 2.158\n",
      "Train Epoch: 7 [11% 40/352]\tLoss: 0.231035\tData (t) 1.646\tBatch (t) 1.781\n",
      "Train Epoch: 7 [17% 60/352]\tLoss: 0.122125\tData (t) 1.890\tBatch (t) 2.219\n",
      "Train Epoch: 7 [23% 80/352]\tLoss: 0.325849\tData (t) 1.874\tBatch (t) 2.065\n",
      "Train Epoch: 7 [28% 100/352]\tLoss: 0.309335\tData (t) 2.037\tBatch (t) 2.219\n",
      "Train Epoch: 7 [34% 120/352]\tLoss: 0.196987\tData (t) 2.036\tBatch (t) 2.067\n",
      "Train Epoch: 7 [40% 140/352]\tLoss: 0.155884\tData (t) 2.037\tBatch (t) 2.068\n",
      "Train Epoch: 7 [45% 160/352]\tLoss: 0.233568\tData (t) 2.039\tBatch (t) 2.071\n",
      "Train Epoch: 7 [51% 180/352]\tLoss: 0.283979\tData (t) 2.036\tBatch (t) 2.071\n",
      "Train Epoch: 7 [57% 200/352]\tLoss: 0.191120\tData (t) 2.034\tBatch (t) 2.065\n",
      "Train Epoch: 7 [62% 220/352]\tLoss: 0.239669\tData (t) 2.036\tBatch (t) 2.068\n",
      "Train Epoch: 7 [68% 240/352]\tLoss: 0.208430\tData (t) 2.037\tBatch (t) 2.069\n",
      "Train Epoch: 7 [74% 260/352]\tLoss: 0.321767\tData (t) 2.040\tBatch (t) 2.073\n",
      "Train Epoch: 7 [80% 280/352]\tLoss: 0.287314\tData (t) 2.036\tBatch (t) 2.067\n",
      "Train Epoch: 7 [85% 300/352]\tLoss: 0.208860\tData (t) 2.035\tBatch (t) 2.066\n",
      "Train Epoch: 7 [91% 320/352]\tLoss: 0.295566\tData (t) 2.023\tBatch (t) 2.055\n",
      "Train Epoch: 7 [97% 340/352]\tLoss: 0.207753\tData (t) 2.032\tBatch (t) 2.068\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.4338   Acc: 79.14: 100% 40/40 [00:41<00:00,  1.04s/it]\n",
      "Val acc at epoch 7: 79.14\n",
      "Saving model to ./config5_8.pt\n",
      "Train Epoch: 8 [0% 0/352]\tLoss: 0.195034\tData (t) 7.124\tBatch (t) 7.371\n",
      "Train Epoch: 8 [6% 20/352]\tLoss: 0.152610\tData (t) 2.075\tBatch (t) 2.118\n",
      "Train Epoch: 8 [11% 40/352]\tLoss: 0.226032\tData (t) 2.016\tBatch (t) 2.047\n",
      "Train Epoch: 8 [17% 60/352]\tLoss: 0.197329\tData (t) 2.047\tBatch (t) 2.079\n",
      "Train Epoch: 8 [23% 80/352]\tLoss: 0.252475\tData (t) 2.033\tBatch (t) 2.064\n",
      "Train Epoch: 8 [28% 100/352]\tLoss: 0.219015\tData (t) 2.027\tBatch (t) 2.059\n",
      "Train Epoch: 8 [34% 120/352]\tLoss: 0.313335\tData (t) 2.034\tBatch (t) 2.065\n",
      "Train Epoch: 8 [40% 140/352]\tLoss: 0.227683\tData (t) 2.013\tBatch (t) 2.045\n",
      "Train Epoch: 8 [45% 160/352]\tLoss: 0.226277\tData (t) 1.821\tBatch (t) 1.854\n",
      "Train Epoch: 8 [51% 180/352]\tLoss: 0.163840\tData (t) 1.791\tBatch (t) 1.822\n",
      "Train Epoch: 8 [57% 200/352]\tLoss: 0.193476\tData (t) 1.825\tBatch (t) 1.865\n",
      "Train Epoch: 8 [62% 220/352]\tLoss: 0.249248\tData (t) 1.667\tBatch (t) 1.776\n",
      "Train Epoch: 8 [68% 240/352]\tLoss: 0.174817\tData (t) 1.797\tBatch (t) 1.884\n",
      "Train Epoch: 8 [74% 260/352]\tLoss: 0.205508\tData (t) 1.843\tBatch (t) 1.973\n",
      "Train Epoch: 8 [80% 280/352]\tLoss: 0.244987\tData (t) 1.826\tBatch (t) 1.948\n",
      "Train Epoch: 8 [85% 300/352]\tLoss: 0.199434\tData (t) 1.710\tBatch (t) 1.771\n",
      "Train Epoch: 8 [91% 320/352]\tLoss: 0.147182\tData (t) 1.808\tBatch (t) 1.848\n",
      "Train Epoch: 8 [97% 340/352]\tLoss: 0.146173\tData (t) 2.031\tBatch (t) 2.077\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.4808   Acc: 79.19: 100% 40/40 [00:37<00:00,  1.07it/s]\n",
      "Val acc at epoch 8: 79.19\n",
      "Saving model to ./config5_9.pt\n",
      "Train Epoch: 9 [0% 0/352]\tLoss: 0.243776\tData (t) 5.230\tBatch (t) 5.540\n",
      "Train Epoch: 9 [6% 20/352]\tLoss: 0.252624\tData (t) 2.078\tBatch (t) 2.115\n",
      "Train Epoch: 9 [11% 40/352]\tLoss: 0.300203\tData (t) 2.010\tBatch (t) 2.041\n",
      "Train Epoch: 9 [17% 60/352]\tLoss: 0.140946\tData (t) 2.052\tBatch (t) 2.084\n",
      "Train Epoch: 9 [23% 80/352]\tLoss: 0.250485\tData (t) 2.028\tBatch (t) 2.064\n",
      "Train Epoch: 9 [28% 100/352]\tLoss: 0.155113\tData (t) 2.031\tBatch (t) 2.063\n",
      "Train Epoch: 9 [34% 120/352]\tLoss: 0.139779\tData (t) 2.042\tBatch (t) 2.075\n",
      "Train Epoch: 9 [40% 140/352]\tLoss: 0.185955\tData (t) 2.043\tBatch (t) 2.076\n",
      "Train Epoch: 9 [45% 160/352]\tLoss: 0.254471\tData (t) 2.041\tBatch (t) 2.072\n",
      "Train Epoch: 9 [51% 180/352]\tLoss: 0.172319\tData (t) 2.036\tBatch (t) 2.067\n",
      "Train Epoch: 9 [57% 200/352]\tLoss: 0.211234\tData (t) 2.028\tBatch (t) 2.059\n",
      "Train Epoch: 9 [62% 220/352]\tLoss: 0.146912\tData (t) 2.035\tBatch (t) 2.068\n",
      "Train Epoch: 9 [68% 240/352]\tLoss: 0.217988\tData (t) 2.038\tBatch (t) 2.070\n",
      "Train Epoch: 9 [74% 260/352]\tLoss: 0.305107\tData (t) 2.039\tBatch (t) 2.073\n",
      "Train Epoch: 9 [80% 280/352]\tLoss: 0.193389\tData (t) 2.035\tBatch (t) 2.079\n",
      "Train Epoch: 9 [85% 300/352]\tLoss: 0.283668\tData (t) 2.036\tBatch (t) 2.077\n",
      "Train Epoch: 9 [91% 320/352]\tLoss: 0.142301\tData (t) 2.024\tBatch (t) 2.067\n",
      "Train Epoch: 9 [97% 340/352]\tLoss: 0.180751\tData (t) 2.028\tBatch (t) 2.060\n",
      "********************************************************************************\n",
      "Starting eval on validation split\n",
      "Val loss: 1.4938   Acc: 79.30: 100% 40/40 [00:37<00:00,  1.06it/s]\n",
      "Val acc at epoch 9: 79.30\n",
      "Saving model to ./config5_10.pt\n",
      "✅ Configuration 5 completed and backed up to Drive!\n"
     ]
    }
   ],
   "source": [
    "# Configuration 5: lr=1e-6, wd=1e-4, epochs=10, batch_size=256, timm_aug=False\n",
    "!python $CODE_DIR/finetune.py --lr 1e-6 --wd 1e-4 --epochs 10 --batch-size 256 --data-location $DATA_DIR --name \"config5\"\n",
    "\n",
    "# Backup model to Google Drive\n",
    "!cp config5_*.pt \"/content/drive/MyDrive/Colab Notebooks/\"\n",
    "print(\"✅ Configuration 5 completed and backed up to Drive!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "b_-KAJBYR4tH",
    "TmkIYFQuR4tI"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
