{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5iLERMCdFzy"
      },
      "source": [
        "# ResNet18 Finetuning on CIFAR-10\n",
        "\n",
        "This notebook:\n",
        "- Takes a ResNet18 network pretrained on ImageNet as base point, then finetune on CIFAR-10\n",
        "- Uses different finetuning hyperparameters to obtain different model checkpoints\n",
        "- Follows heDeepResidualLearning2016 training configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J_BOdLFdFz1"
      },
      "source": [
        "## Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7K9SW4LdFz1"
      },
      "outputs": [],
      "source": [
        "LOCAL = True\n",
        "\n",
        "# if run locally:\n",
        "if LOCAL:\n",
        "    ROOT_DIR = \"/Users/Yang/Desktop/research-model-merge/playground/merge_soup-resnet18-cifar10\"\n",
        "    DATA_DIR = \"/Users/Yang/Desktop/research-model-merge/datasets\"\n",
        "    PROJECT_ROOT = \"/Users/Yang/Desktop/research-model-merge\"\n",
        "else:\n",
        "    # on Colab\n",
        "    ROOT_DIR = \"/content/research-model-merge/playground/merge_soup-resnet18-cifar10\"\n",
        "    DATA_DIR = \"/content/research-model-merge/datasets\"\n",
        "    PROJECT_ROOT = \"/content/research-model-merge\"\n",
        "    DRIVE_DIR = \"/content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p6L2zywdFz3"
      },
      "source": [
        "If using Colab, mount Google Drive to save checkpoints persistently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py7IP8QzdFz3",
        "outputId": "b7579288-f567-4267-da9f-b509e5e6d5cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "if not LOCAL:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_J17ToIdFz3"
      },
      "source": [
        "Clone the repository and install dependencies on Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUeZEn8QdFz3",
        "outputId": "d2d03105-628b-4a36-9cba-9c95b3a9c5e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into '/content/research-model-merge'...\n",
            "remote: Enumerating objects: 92, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 92 (delta 34), reused 90 (delta 32), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (92/92), 1.54 MiB | 4.97 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n",
            "✅ Repository cloned and dependencies installed!\n"
          ]
        }
      ],
      "source": [
        "if not LOCAL:\n",
        "    # remove the dir if exists\n",
        "    !rm -rf research-model-merge\n",
        "    # Clone the repository\n",
        "    !git clone https://github.com/nbzy1995/research-model-merge.git /content/research-model-merge\n",
        "\n",
        "    # Install dependencies\n",
        "    !pip install --quiet --upgrade pip\n",
        "    !pip install -q -r research-model-merge/requirements.txt\n",
        "    print(\"✅ Repository cloned and dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "U38oVMw-dFz4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "from typing import Dict, Any\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Add project root to path\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_ROOT)\n",
        "\n",
        "# Add utils to path\n",
        "if ROOT_DIR not in sys.path:\n",
        "    sys.path.insert(0, ROOT_DIR)\n",
        "\n",
        "from datasets.cifar10 import CIFAR10\n",
        "\n",
        "from datasets.cifar10 import CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9a4J_FmdFz4",
        "outputId": "3c03988b-95e0-40c4-817d-931d9e362c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 System Information:\n",
            "Python version: Python 3.12.11\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "GPU device: Tesla T4\n",
            "GPU memory: 15.8 GB\n",
            "CUDA version: 12.6\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability and system info\n",
        "import subprocess\n",
        "\n",
        "print(\"🔍 System Information:\")\n",
        "print(f\"Python version: {subprocess.check_output(['python', '--version']).decode().strip()}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "else:\n",
        "    if LOCAL:\n",
        "        print(\"⚠️ No GPU available! Training will be slow on CPU.\")\n",
        "    else:\n",
        "        print(\"❌ No GPU available! Please enable GPU runtime in Colab.\")\n",
        "        print(\"Runtime > Change runtime type > Hardware accelerator > GPU\")\n",
        "    DEVICE = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWvpzjNfdFz5"
      },
      "source": [
        "## Dataset Preparation\n",
        "\n",
        "Using the shared CIFAR10 dataset class from `datasets/cifar10.py`:\n",
        "- Training: 98% of original training set (49,000 images)\n",
        "- Validation: 2% of original training set (1,000 images)  \n",
        "- Test: Official CIFAR-10 test set (10,000 images)\n",
        "- Persistent indices ensure consistent splits across all experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPFCQQTsdFz5",
        "outputId": "2291d585-d9c0-4732-b0f3-b4ffebc62048"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:08<00:00, 20.7MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dataset loaded:\n",
            "   Train samples: 49000\n",
            "   Val samples: 1000\n",
            "   Test samples: 10000\n",
            "   Classnames: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        }
      ],
      "source": [
        "# Create CIFAR-10 dataset using shared dataset class\n",
        "# This uses persistent indices for reproducible splits\n",
        "dataset = CIFAR10(\n",
        "    data_location=DATA_DIR,\n",
        "    batch_size=256,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "train_loader = dataset.train_loader\n",
        "val_loader = dataset.val_loader\n",
        "test_loader = dataset.test_loader\n",
        "\n",
        "print(f\"✅ Dataset loaded:\")\n",
        "print(f\"   Train samples: {len(dataset.train_sampler)}\")\n",
        "print(f\"   Val samples: {len(dataset.val_sampler)}\")\n",
        "print(f\"   Test samples: {len(dataset.test_dataset)}\")\n",
        "print(f\"   Classnames: {dataset.classnames}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5pnCHDRdFz5"
      },
      "source": [
        "## Finetuning Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "c1W8nsZJdFz5"
      },
      "outputs": [],
      "source": [
        "def cosine_lr_schedule(optimizer, epoch, total_epochs, warmup_epochs, base_lr):\n",
        "    \"\"\"\n",
        "    Cosine learning rate schedule with linear warmup.\n",
        "    Following Git Re-Basin configuration.\n",
        "    \"\"\"\n",
        "    if epoch < warmup_epochs:\n",
        "        # Linear warmup from 1e-6 to base_lr\n",
        "        lr = 1e-6 + (base_lr - 1e-6) * epoch / warmup_epochs\n",
        "    else:\n",
        "        # Cosine decay from base_lr to 0\n",
        "        progress = (epoch - warmup_epochs) / (total_epochs - warmup_epochs)\n",
        "        lr = base_lr * 0.5 * (1 + np.cos(np.pi * progress))\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NQYMn18hdFz6"
      },
      "outputs": [],
      "source": [
        "def step_lr_schedule(optimizer, epoch, total_epochs, warmup_epochs, base_lr):\n",
        "    \"\"\"\n",
        "    Following heDeepResidualLearning2016.\n",
        "    \"\"\"\n",
        "    if epoch < warmup_epochs:\n",
        "        lr = base_lr\n",
        "    else:\n",
        "        lr = base_lr * 0.1\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jMDwphc0dFz6"
      },
      "outputs": [],
      "source": [
        "def finetune_resnet(\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    model_save_location: str = '.',\n",
        "    batch_size: int = 256,\n",
        "    epochs: int = 10,\n",
        "    warmup_epochs: int = 5,\n",
        "    lr: float = 0.1,\n",
        "    wd: float = 1e-4,\n",
        "    momentum: float = 0.9,\n",
        "    name: str = 'config1',\n",
        "    log_interval: int = 20,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Finetune ResNet18 (pretrained on ImageNet) on CIFAR-10.\n",
        "\n",
        "    Following He 2016 training configuration:\n",
        "    - SGD optimizer with momentum=0.9\n",
        "    - Weight decay (default 1e-4)\n",
        "    - Step LR schedule with 5-epoch warmup\n",
        "    - Warmup: 1e-6 -> lr over 5 epochs\n",
        "    - Step decay: lr -> 0.1*lr after warmup\n",
        "    \"\"\"\n",
        "    os.makedirs(model_save_location, exist_ok=True)\n",
        "\n",
        "    # Load pretrained ResNet18 and modify for CIFAR-10\n",
        "    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    # Modify first conv layer for 32x32 input (CIFAR-10)\n",
        "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "    # Remove maxpool layer (too aggressive for 32x32 images)\n",
        "    model.maxpool = nn.Identity()\n",
        "\n",
        "    # Replace final FC layer for CIFAR-10 (10 classes)\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_features, 10)\n",
        "\n",
        "    model = model.to(DEVICE)\n",
        "\n",
        "    # Optimizer: SGD with momentum\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=lr,\n",
        "        momentum=momentum,\n",
        "        weight_decay=wd\n",
        "    )\n",
        "\n",
        "    # Loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training history\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'val_acc': [],\n",
        "        'lr': []\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Starting training: {name}\")\n",
        "    print(f\"Config: lr={lr}, wd={wd}, epochs={epochs}, batch_size={batch_size}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        # Update learning rate\n",
        "        current_lr = step_lr_schedule(optimizer, epoch, epochs, warmup_epochs, lr)\n",
        "        history['lr'].append(current_lr)\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss_accum = 0.0\n",
        "        train_batches = 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]')\n",
        "        for i, (inputs, labels) in enumerate(pbar):\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss_accum += loss.item()\n",
        "            train_batches += 1\n",
        "\n",
        "            if i % log_interval == 0:\n",
        "                pbar.set_postfix({\n",
        "                    'loss': f'{loss.item():.4f}',\n",
        "                    'lr': f'{current_lr:.6f}'\n",
        "                })\n",
        "\n",
        "        train_loss = train_loss_accum / train_batches\n",
        "        history['train_loss'].append(train_loss)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss_accum = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Val]')\n",
        "            for inputs, labels in pbar:\n",
        "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss_accum += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                pbar.set_postfix({\n",
        "                    'loss': f'{loss.item():.4f}',\n",
        "                    'acc': f'{100.*correct/total:.2f}%'\n",
        "                })\n",
        "\n",
        "        val_loss = val_loss_accum / len(val_loader)\n",
        "        val_acc = correct / total\n",
        "\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs} Summary:\")\n",
        "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
        "        print(f\"  Val Loss:   {val_loss:.4f}\")\n",
        "        print(f\"  Val Acc:    {100*val_acc:.2f}%\")\n",
        "        print(f\"  LR:         {current_lr:.6f}\\n\")\n",
        "\n",
        "        # Save checkpoint after each epoch\n",
        "        checkpoint_path = os.path.join(model_save_location, f'{name}_epoch{epoch+1}.pt')\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "        print(f\"✅ Saved checkpoint: {checkpoint_path}\")\n",
        "\n",
        "    result = {\n",
        "        'history': history,\n",
        "        'config': {\n",
        "            'model_save_location': model_save_location,\n",
        "            'batch_size': batch_size,\n",
        "            'epochs': epochs,\n",
        "            'warmup_epochs': warmup_epochs,\n",
        "            'lr': lr,\n",
        "            'wd': wd,\n",
        "            'momentum': momentum,\n",
        "            'name': name,\n",
        "        },\n",
        "    }\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D97E3MshdFz6"
      },
      "source": [
        "## Run Training with Multiple Configurations\n",
        "\n",
        "We train 5 different configurations with varying learning rates and weight decay values:\n",
        "\n",
        "1. **Config 1**: lr=0.1, wd=1e-4 (He 2016 baseline)\n",
        "2. **Config 2**: lr=0.05, wd=1e-4\n",
        "3. **Config 3**: lr=0.01, wd=1e-4\n",
        "4. **Config 4**: lr=0.1, wd=1e-3\n",
        "5. **Config 5**: lr=0.1, wd=1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xHUPDkP3dFz6"
      },
      "outputs": [],
      "source": [
        "# Checkpoint directory\n",
        "if LOCAL:\n",
        "    checkpoint_dir = f\"{ROOT_DIR}/checkpoints\"\n",
        "else:\n",
        "    checkpoint_dir = f\"{DRIVE_DIR}/checkpoints\"\n",
        "\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Define configurations\n",
        "configs = [\n",
        "    dict(lr=0.1, wd=1e-4, name='config1'),\n",
        "    dict(lr=0.05, wd=1e-4, name='config2'),\n",
        "    dict(lr=0.01, wd=1e-4, name='config3'),\n",
        "    dict(lr=0.1, wd=1e-3, name='config4'),\n",
        "    dict(lr=0.1, wd=1e-5, name='config5'),\n",
        "]\n",
        "\n",
        "# Common parameters\n",
        "common = dict(\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    model_save_location=checkpoint_dir,\n",
        "    batch_size=258,\n",
        "    epochs=10,\n",
        "    warmup_epochs=5,\n",
        "    momentum=0.9,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgqYaU7jdFz6",
        "outputId": "2fff1741-583d-4992-c639-dc5eaefba67a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "################################################################################\n",
            "Running configuration: config1\n",
            "  LR: 0.1, WD: 0.0001\n",
            "################################################################################\n",
            "\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 111MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Starting training: config1\n",
            "Config: lr=0.1, wd=0.0001, epochs=10, batch_size=258\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 [Train]: 100%|██████████| 192/192 [00:47<00:00,  4.08it/s, loss=2.0856, lr=0.100000]\n",
            "Epoch 1/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  7.86it/s, loss=2.1194, acc=19.30%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/10 Summary:\n",
            "  Train Loss: 3.3916\n",
            "  Val Loss:   2.1219\n",
            "  Val Acc:    19.30%\n",
            "  LR:         0.100000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config1_epoch1.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 [Train]: 100%|██████████| 192/192 [00:42<00:00,  4.52it/s, loss=1.8862, lr=0.100000]\n",
            "Epoch 2/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  6.99it/s, loss=2.0189, acc=29.20%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2/10 Summary:\n",
            "  Train Loss: 2.0032\n",
            "  Val Loss:   1.9286\n",
            "  Val Acc:    29.20%\n",
            "  LR:         0.100000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config1_epoch2.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 [Train]: 100%|██████████| 192/192 [00:42<00:00,  4.56it/s, loss=1.6816, lr=0.100000]\n",
            "Epoch 3/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.16it/s, loss=1.7781, acc=36.40%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3/10 Summary:\n",
            "  Train Loss: 1.7881\n",
            "  Val Loss:   1.6944\n",
            "  Val Acc:    36.40%\n",
            "  LR:         0.100000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config1_epoch3.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.75it/s, loss=1.6208, lr=0.100000]\n",
            "Epoch 4/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.46it/s, loss=1.6536, acc=44.50%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4/10 Summary:\n",
            "  Train Loss: 1.6342\n",
            "  Val Loss:   1.5335\n",
            "  Val Acc:    44.50%\n",
            "  LR:         0.100000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config1_epoch4.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.78it/s, loss=1.6547, lr=0.100000]\n",
            "Epoch 5/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.54it/s, loss=1.5400, acc=48.10%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5/10 Summary:\n",
            "  Train Loss: 1.5305\n",
            "  Val Loss:   1.4313\n",
            "  Val Acc:    48.10%\n",
            "  LR:         0.100000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config1_epoch5.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.76it/s, loss=1.5412, lr=0.010000]\n",
            "Epoch 6/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.73it/s, loss=1.3661, acc=51.50%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6/10 Summary:\n",
            "  Train Loss: 1.4176\n",
            "  Val Loss:   1.3102\n",
            "  Val Acc:    51.50%\n",
            "  LR:         0.010000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config1_epoch6.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 [Train]: 100%|██████████| 192/192 [00:39<00:00,  4.84it/s, loss=1.4743, lr=0.010000]\n",
            "Epoch 7/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  6.83it/s, loss=1.3420, acc=52.80%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7/10 Summary:\n",
            "  Train Loss: 1.3884\n",
            "  Val Loss:   1.2945\n",
            "  Val Acc:    52.80%\n",
            "  LR:         0.010000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config1_epoch7.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 [Train]: 100%|██████████| 192/192 [00:41<00:00,  4.60it/s, loss=1.4330, lr=0.010000]\n",
            "Epoch 8/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  6.35it/s, loss=1.3265, acc=53.30%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8/10 Summary:\n",
            "  Train Loss: 1.3623\n",
            "  Val Loss:   1.2810\n",
            "  Val Acc:    53.30%\n",
            "  LR:         0.010000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config1_epoch8.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.79it/s, loss=1.3260, lr=0.010000]\n",
            "Epoch 9/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.55it/s, loss=1.2574, acc=55.80%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9/10 Summary:\n",
            "  Train Loss: 1.3506\n",
            "  Val Loss:   1.2496\n",
            "  Val Acc:    55.80%\n",
            "  LR:         0.010000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config1_epoch9.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.76it/s, loss=1.3285, lr=0.010000]\n",
            "Epoch 10/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.74it/s, loss=1.2544, acc=54.40%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10/10 Summary:\n",
            "  Train Loss: 1.3290\n",
            "  Val Loss:   1.2477\n",
            "  Val Acc:    54.40%\n",
            "  LR:         0.010000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config1_epoch10.pt\n",
            "\n",
            "✅ config1 completed!\n",
            "\n",
            "\n",
            "################################################################################\n",
            "Running configuration: config2\n",
            "  LR: 0.05, WD: 0.0001\n",
            "################################################################################\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Starting training: config2\n",
            "Config: lr=0.05, wd=0.0001, epochs=10, batch_size=258\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.73it/s, loss=0.7658, lr=0.050000]\n",
            "Epoch 1/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.74it/s, loss=0.8860, acc=71.70%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/10 Summary:\n",
            "  Train Loss: 1.3856\n",
            "  Val Loss:   0.8668\n",
            "  Val Acc:    71.70%\n",
            "  LR:         0.050000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config2_epoch1.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.73it/s, loss=0.5989, lr=0.050000]\n",
            "Epoch 2/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.49it/s, loss=0.4233, acc=82.70%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2/10 Summary:\n",
            "  Train Loss: 0.6969\n",
            "  Val Loss:   0.5022\n",
            "  Val Acc:    82.70%\n",
            "  LR:         0.050000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config2_epoch2.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.72it/s, loss=0.5196, lr=0.050000]\n",
            "Epoch 3/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.39it/s, loss=0.4116, acc=83.90%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3/10 Summary:\n",
            "  Train Loss: 0.5513\n",
            "  Val Loss:   0.4726\n",
            "  Val Acc:    83.90%\n",
            "  LR:         0.050000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config2_epoch3.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 [Train]: 100%|██████████| 192/192 [00:42<00:00,  4.53it/s, loss=0.5107, lr=0.050000]\n",
            "Epoch 4/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.54it/s, loss=0.3731, acc=85.80%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4/10 Summary:\n",
            "  Train Loss: 0.4708\n",
            "  Val Loss:   0.4287\n",
            "  Val Acc:    85.80%\n",
            "  LR:         0.050000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config2_epoch4.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.78it/s, loss=0.4881, lr=0.050000]\n",
            "Epoch 5/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  7.29it/s, loss=0.3124, acc=88.10%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5/10 Summary:\n",
            "  Train Loss: 0.4173\n",
            "  Val Loss:   0.3427\n",
            "  Val Acc:    88.10%\n",
            "  LR:         0.050000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config2_epoch5.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.76it/s, loss=0.2718, lr=0.005000]\n",
            "Epoch 6/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  6.50it/s, loss=0.1923, acc=92.50%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6/10 Summary:\n",
            "  Train Loss: 0.2988\n",
            "  Val Loss:   0.2132\n",
            "  Val Acc:    92.50%\n",
            "  LR:         0.005000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config2_epoch6.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.77it/s, loss=0.2711, lr=0.005000]\n",
            "Epoch 7/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  7.72it/s, loss=0.1908, acc=92.50%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7/10 Summary:\n",
            "  Train Loss: 0.2567\n",
            "  Val Loss:   0.2092\n",
            "  Val Acc:    92.50%\n",
            "  LR:         0.005000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config2_epoch7.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.75it/s, loss=0.1695, lr=0.005000]\n",
            "Epoch 8/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.87it/s, loss=0.1987, acc=92.70%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8/10 Summary:\n",
            "  Train Loss: 0.2396\n",
            "  Val Loss:   0.2070\n",
            "  Val Acc:    92.70%\n",
            "  LR:         0.005000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config2_epoch8.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 [Train]: 100%|██████████| 192/192 [00:42<00:00,  4.53it/s, loss=0.2116, lr=0.005000]\n",
            "Epoch 9/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.79it/s, loss=0.1777, acc=92.40%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9/10 Summary:\n",
            "  Train Loss: 0.2273\n",
            "  Val Loss:   0.1943\n",
            "  Val Acc:    92.40%\n",
            "  LR:         0.005000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config2_epoch9.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.76it/s, loss=0.1929, lr=0.005000]\n",
            "Epoch 10/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.01it/s, loss=0.1964, acc=92.10%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10/10 Summary:\n",
            "  Train Loss: 0.2162\n",
            "  Val Loss:   0.1913\n",
            "  Val Acc:    92.10%\n",
            "  LR:         0.005000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config2_epoch10.pt\n",
            "\n",
            "✅ config2 completed!\n",
            "\n",
            "\n",
            "################################################################################\n",
            "Running configuration: config3\n",
            "  LR: 0.01, WD: 0.0001\n",
            "################################################################################\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Starting training: config3\n",
            "Config: lr=0.01, wd=0.0001, epochs=10, batch_size=258\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.75it/s, loss=0.6690, lr=0.010000]\n",
            "Epoch 1/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.51it/s, loss=0.5972, acc=78.60%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/10 Summary:\n",
            "  Train Loss: 1.2094\n",
            "  Val Loss:   0.6344\n",
            "  Val Acc:    78.60%\n",
            "  LR:         0.010000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config3_epoch1.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.74it/s, loss=0.5391, lr=0.010000]\n",
            "Epoch 2/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.62it/s, loss=0.3834, acc=84.00%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2/10 Summary:\n",
            "  Train Loss: 0.6808\n",
            "  Val Loss:   0.4346\n",
            "  Val Acc:    84.00%\n",
            "  LR:         0.010000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config3_epoch2.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.77it/s, loss=0.4509, lr=0.010000]\n",
            "Epoch 3/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.60it/s, loss=0.2854, acc=87.90%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3/10 Summary:\n",
            "  Train Loss: 0.5279\n",
            "  Val Loss:   0.3552\n",
            "  Val Acc:    87.90%\n",
            "  LR:         0.010000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config3_epoch3.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.74it/s, loss=0.4766, lr=0.010000]\n",
            "Epoch 4/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.00it/s, loss=0.2876, acc=88.10%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4/10 Summary:\n",
            "  Train Loss: 0.4307\n",
            "  Val Loss:   0.3209\n",
            "  Val Acc:    88.10%\n",
            "  LR:         0.010000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config3_epoch4.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 [Train]: 100%|██████████| 192/192 [00:41<00:00,  4.59it/s, loss=0.3054, lr=0.010000]\n",
            "Epoch 5/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.67it/s, loss=0.2801, acc=88.90%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5/10 Summary:\n",
            "  Train Loss: 0.3735\n",
            "  Val Loss:   0.3256\n",
            "  Val Acc:    88.90%\n",
            "  LR:         0.010000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config3_epoch5.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 [Train]: 100%|██████████| 192/192 [00:40<00:00,  4.74it/s, loss=0.2808, lr=0.001000]\n",
            "Epoch 6/10 [Val]: 100%|██████████| 4/4 [00:00<00:00,  9.13it/s, loss=0.2248, acc=91.30%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6/10 Summary:\n",
            "  Train Loss: 0.2928\n",
            "  Val Loss:   0.2556\n",
            "  Val Acc:    91.30%\n",
            "  LR:         0.001000\n",
            "\n",
            "✅ Saved checkpoint: /content/drive/MyDrive/research-model_merge-shared/merge_soup-resnet18-cifar10/checkpoints/config3_epoch6.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 [Train]:  57%|█████▋    | 109/192 [00:22<00:16,  4.92it/s, loss=0.2151, lr=0.001000]"
          ]
        }
      ],
      "source": [
        "# Run all configurations\n",
        "results = []\n",
        "\n",
        "for config in configs:\n",
        "    run_config = {**common, **config}\n",
        "    print(f\"\\n{'#'*80}\")\n",
        "    print(f\"Running configuration: {config['name']}\")\n",
        "    print(f\"  LR: {config['lr']}, WD: {config['wd']}\")\n",
        "    print(f\"{'#'*80}\\n\")\n",
        "\n",
        "    result = finetune_resnet(**run_config)\n",
        "    results.append(result)\n",
        "\n",
        "    print(f\"\\n✅ {config['name']} completed!\\n\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"All configurations completed!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk7RQnUldFz6"
      },
      "source": [
        "## Summary of Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JiyG6KfdFz7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create summary table\n",
        "summary = []\n",
        "for r in results:\n",
        "    cfg = r['config']\n",
        "    hist = r['history']\n",
        "    summary.append({\n",
        "        'name': cfg['name'],\n",
        "        'lr': cfg['lr'],\n",
        "        'wd': cfg['wd'],\n",
        "        'final_train_loss': hist['train_loss'][-1],\n",
        "        'final_val_loss': hist['val_loss'][-1],\n",
        "        'final_val_acc': f\"{100*hist['val_acc'][-1]:.2f}%\",\n",
        "        'best_val_acc': f\"{100*max(hist['val_acc']):.2f}%\",\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(summary)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Training Summary\")\n",
        "print(\"=\"*80)\n",
        "print(df.to_string(index=False))\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save summary\n",
        "df.to_csv(f\"{checkpoint_dir}/training_summary.csv\", index=False)\n",
        "print(f\"\\n✅ Summary saved to {checkpoint_dir}/training_summary.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLv1wx4EdFz7"
      },
      "source": [
        "## Plot Training Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADKn41FYdFz7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Plot 1: Training Loss\n",
        "for r in results:\n",
        "    axes[0, 0].plot(r['history']['train_loss'], label=r['config']['name'])\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Train Loss')\n",
        "axes[0, 0].set_title('Training Loss')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True)\n",
        "\n",
        "# Plot 2: Validation Loss\n",
        "for r in results:\n",
        "    axes[0, 1].plot(r['history']['val_loss'], label=r['config']['name'])\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Validation Loss')\n",
        "axes[0, 1].set_title('Validation Loss')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True)\n",
        "\n",
        "# Plot 3: Validation Accuracy\n",
        "for r in results:\n",
        "    axes[1, 0].plot([100*x for x in r['history']['val_acc']], label=r['config']['name'])\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Validation Accuracy (%)')\n",
        "axes[1, 0].set_title('Validation Accuracy')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True)\n",
        "\n",
        "# Plot 4: Learning Rate\n",
        "for r in results:\n",
        "    axes[1, 1].plot(r['history']['lr'], label=r['config']['name'])\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Learning Rate')\n",
        "axes[1, 1].set_title('Learning Rate Schedule')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True)\n",
        "axes[1, 1].set_yscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{checkpoint_dir}/training_curves.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"✅ Training curves saved to {checkpoint_dir}/training_curves.png\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
